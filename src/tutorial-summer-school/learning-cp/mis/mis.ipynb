{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS\n",
    "In a graph, the maximal independent set, also known as maximal stable set is an independent set that is not a subset of any other independent set. In other words, it is a set of vertices such that no two vertices in the set are adjacent. In this notebook, we will build a learning-based model to find the maximal independent set in a graph.\n",
    "\n",
    "<img src=\"img/Independent_set_graph.png\" alt=\"Solved MIS\" style=\"width:400px; height:400px;\">\n",
    "\n",
    "SeaPearl currently supports learning-based value selection models trained with Reinforcement Learning. To train Reinforcement Learning agents, we start by generating training instances and we let the agent learn a value selection heuristic. Like all other Reinforcement Learning tasks, we need to define a reward function, a state representation and an action space. Finally, we also need to build a neural network that will learn the value selection heuristic. All of these components will be defined in the following sections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We will begin by activating the environment and importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\leobo\\Desktop\\École\\Poly\\SeaPearl\\SeaPearlZoo.jl`\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe project dependencies or compat requirements have changed since the manifest was last resolved.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIt is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Pkg.API C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.8\\Pkg\\src\\API.jl:1527\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ReinforcementLearning"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using Pkg\n",
    "Pkg.activate(\"../../../../\")\n",
    "Pkg.instantiate()\n",
    "using SeaPearl\n",
    "using Flux\n",
    "using LightGraphs\n",
    "using Random\n",
    "using BSON: @save, @load\n",
    "using ReinforcementLearning\n",
    "using CSV\n",
    "const RL = ReinforcementLearning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating instances\n",
    "\n",
    "SeaPearl provides a number of instance generators, including one for the MIS problem. Under the hood, this generator creates Barabasi-Albert graphs with `n` vertices. The graphs are grown by adding new vertices to an initial that has `k` vertices. New vertices are connected by `k` edges to `k` different vertices already present in the system by preferential attachment. The resulting graphs are undirected.\n",
    "\n",
    "<img src=\"img/450px-Barabasi_albert_graph.png\" alt=\"Barabasi-Albert Graph\" style=\"width:600px; height:200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeaPearl.MaximumIndependentSetGenerator(8, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numInitialVertices = 3\n",
    "numNewVertices = 8\n",
    "instance_generator = SeaPearl.MaximumIndependentSetGenerator(numNewVertices, numInitialVertices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reinforcement Learning setup\n",
    "\n",
    "### The state representation\n",
    "In SeaPearl, the state $s_t$ is defined as a pair $s_t = (P_t, x_t)$, with $P_t$ a partially solved combinatorial optimization problem and $x_t$ a variable selected at time $t$ of an episode. A terminal episode is reached if all variables are fixed or if a failure is detected.\n",
    "\n",
    "### The action space\n",
    "Given a state $s_t = (P_t, x_t)$, an action $a_t$ represents the selection of a value $v$ for the variable $x_t$. The action space is defined as the set of all possible values for the variable $x_t$ at time $t$.\n",
    "\n",
    "### The transition function\n",
    "Given a state $s_t = (P_t, x_t)$ and an action $a_t = v$, the transition function is comprised of three steps;\n",
    "1. The value of variable $x_{267}$ is assigned as $v$ (i.e., $D(x_{t+1}) = v$).\n",
    "2. The fix-point operation is applied on $P_t$ to prune the domains (i.e., $P_{t+1} = \\text{{fixPoint}}(P_t)$).\n",
    "3. The next variable to branch on is selected (i.e., $x_{t+1} = \\text{{nextVariable}}(P_{t+1})$).\n",
    "This results in a new state $s_{t+1} = (P_{t+1}, x_{t+1})$.\n",
    "\n",
    "\n",
    "### The reward function\n",
    "SeaPearl uses a \"propagation-based reward\". As the goal of the agent is to quickly find a good solution, it needs to learn to effectively prune the search space and move toward promising regions. An intuitive way to configure the reward is to give the agent the objective value, but this information is only available at the end of episodes. In other words, it makes the reward signal extremely sparse. To address this problem, SeaPearl uses both an intermediate reward and a final reward. The intuition behind the intermediate reward is this: it is computed by rewarding the pruning of high values from the variable's domain and penalizing the pruning of low values from the variable's domain. Mathematcially, the intermediate reward is defined as follows:\n",
    "\n",
    "$$\n",
    "\n",
    "r_t^{ub} = \\{ v \\in D_t(x_{\\text{{obj}}}) \\mid v \\notin D_{t+1}(x_{\\text{{obj}}}) \\land v > \\max(D_t(x_{\\text{{obj}}})) \\} \\\\\n",
    "r_t^{lb} = \\{ v \\in D_t(x_{\\text{{obj}}}) \\mid v \\notin D_{t+1}(x_{\\text{{obj}}}) \\land v < \\min(D_t(x_{\\text{{obj}}})) \\} \\\\\n",
    "r^{mid}_t = \\frac{{r_t^{ub} - r_t^{lb}}}{{\\lvert D_1(x_{\\text{{obj}}}) \\rvert}} \\\\\n",
    "r^{end}_t = \\begin{cases} -1 & \\text{{if unfeasible solution found}} \\\\ 0 & \\text{{otherwise}} \\end{cases} \\\\\n",
    "r_{acc} = \\frac{{\\sum_{t=1}^{T} (r^{mid}_t + r^{end}_t)}}{{T-1}}\n",
    "$$\n",
    "\n",
    "## Implementation\n",
    "\n",
    "We will now begin to implement the MIS problem in SeaPearl. To start, we will define the reward, which comes directly from the mathematical definition above. It is implemented in the `GeneralReward` of SeaPearl.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeaPearl.GeneralReward"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = SeaPearl.GeneralReward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neural Network\n",
    "\n",
    "Next up, we need to define the neural network that will learn the value selection function. As the problems can differ in size, the use of graph neural networks (GNNs) is particularly appropriate. GNNs are a class of neural networks that operate on graphs, which means we need to convert the problem instances to graphs. In SeaPearl, we use tripartite graphs, which are graphs with three types of nodes: variables, values and constraints. There is one node for every variable, for every value and for every constraint. The edges are defined as follows:\n",
    " - There is an edge between a variable and a value if the value is in the domain of the variable.\n",
    " - There is an edge between a variable and a constraint if the variable appears in the constraint.\n",
    "\n",
    "Nodes have the following features:\n",
    " - Values have a one-hot encoding of their value. For example, if the domain of a variable is $\\{1, 2, 3\\}$, then the values will have a one-hot encoding of $[1, 2, 3]$.\n",
    " - Constraints have a one-hot encoding of their type (i.e., constraint).\n",
    "\n",
    "Other features can be used in the graph and we will define a featurization for it later on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the experiment\n",
    "\n",
    "In the next cell, we will set up the experiment. We will create structs for the agent and the experiment. We will also define the hyperparameters of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MisExperimentSettings(300, 1, 10, 10, 1, 8, 3, 123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"MisAgentConfig holds parameters for the configuration of the RL agent that will be used\"\"\"\n",
    "\n",
    "struct MisAgentConfig\n",
    "    gamma::Float32  # Discount factor for future rewards\n",
    "    batch_size::Int  # Batch size\n",
    "    output_size::Int  # One for every node\n",
    "    update_horizon::Int  # How many steps to look ahead in the environment\n",
    "    min_replay_history::Int  # Minimum number of transitions to keep in the replay buffer\n",
    "    update_freq::Int  # Number of actions between successive SGD updates\n",
    "    target_update_freq::Int  # Number of actions between target network updates\n",
    "    trajectory_capacity::Int  # Maximum number of trajectories to store in the replay buffer\n",
    "end\n",
    "\n",
    "\"\"\"MisExperimentSettings holds parameters for the configuration of the experiment\"\"\"\n",
    "struct MisExperimentSettings\n",
    "    nbEpisodes::Int # Number of episodes in the training\n",
    "    restartPerInstances::Int # Number of restarts per instance during training\n",
    "    evalFreq::Int # Number of episodes between evaluations; an evalFreq of 20 means that the performance of heuristics -the agent and the other ones, will be evaluated every 20 episodes\n",
    "    nbInstances::Int # Number of instances to train on\n",
    "    nbRandomHeuristics::Int # Number of random heuristics to use for comparison purposes\n",
    "    nbNewVertices::Int \n",
    "    nbInitialVertices::Int\n",
    "    seedEval::Int # Random seed\n",
    "end\n",
    "\n",
    "agent_config = MisAgentConfig(0.99f0, 64, instance_generator.n, 4, 400, 1, 20, 2000)\n",
    "mis_settings = MisExperimentSettings(300, 1, 10, 10, 1, numNewVertices, numInitialVertices, 123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further configuration\n",
    "\n",
    "Next up, we will define additional configurations for the experiment:\n",
    "- The random seed\n",
    "- Number of steps per episode\n",
    "- The update horizon\n",
    "- The device to use (CPU or GPU)\n",
    "- The evaluation frequency\n",
    "- The steps for the explorer\n",
    "- The parameter initialization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#1 (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_per_episode = Int(round(mis_settings.nbNewVertices // 2)) + mis_settings.nbInitialVertices \n",
    "update_horizon = Int(round(n_step_per_episode // 2))\n",
    "device = cpu # change if you have a GPU\n",
    "\n",
    "if device == gpu\n",
    "    CUDA.device!(numDevice)\n",
    "end\n",
    "\n",
    "evalFreq = mis_settings.evalFreq # evaluation frequency, as defined above\n",
    "decay_steps_explorer = Int(floor(mis_settings.nbEpisodes * n_step_per_episode / 2)) # Number of steps after which the explorer will perform exponential decay for epsilon\n",
    "generator = instance_generator # Use the \n",
    "eval_generator = generator\n",
    "\n",
    "rngExp = MersenneTwister(mis_settings.seedEval)\n",
    "init = Flux.glorot_uniform(MersenneTwister(mis_settings.seedEval))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The State Representation\n",
    "\n",
    "The state representation is defined in the `HeterogeneousStateRepresentation` class. It is a heterogeneous state representation, which means that it is comprised of multiple state representations. In this example, we will use the `DefaultFeaturization` and the `HeterogeneousTrajectoryState` state representations. The `DefaultFeaturization` state representation is a featurization that is used by default in SeaPearl and allows the user to select the graph features they want. The available features are the following.\n",
    "### Variable Features:\n",
    "- node_number_of_neighbors\n",
    "- variable_initial_domain_size\n",
    "- variable_domain_size\n",
    "- variable_is_bound\n",
    "- variable_is_branchable\n",
    "- variable_is_objective\n",
    "- variable_assigned_value\n",
    "### Constraint Features\n",
    "- node_number_of_neighbors\n",
    "- constraint_activity\n",
    "- nb_involved_constraint_propagation\n",
    "- nb_not_bounded_variable\n",
    "- constraint_type\n",
    "### Value Features\n",
    "- node_number_of_neighbors\n",
    "- values_raw\n",
    "- values_onehot\n",
    "\n",
    "The featurization is used to convert the problem instance to a graph. The `HeterogeneousTrajectoryState` state representation is a state representation that is used to represent the state at a given point in the resolution of the problem. It contains the variable that is branched on, the feature graph at that point and the available values.\n",
    "\n",
    "### Visual representation\n",
    "\n",
    "The following image shows an example of a state representation. Here:\n",
    "- $f_1$ represents features attached to variables ($X_1, X_2, X_3$)\n",
    "- $f_2$ represents features attached to constraints ($C_1, C_2, C_3$)\n",
    "- $f_3$ represents features attached to values (1, 2, 3)\n",
    "\n",
    "<img src=\"img/state-representation.png\" alt=\"State Representation\" style=\"width:700px; height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defines the features that will be used\n",
    "chosen_features = Dict(\n",
    "    \"node_number_of_neighbors\" => true,\n",
    "    \"constraint_type\" => true,\n",
    "    \"constraint_activity\" => true,\n",
    "    \"nb_not_bounded_variable\" => true,\n",
    "    \"variable_initial_domain_size\" => true,\n",
    "    \"variable_domain_size\" => true,\n",
    "    \"variable_is_objective\" => true,\n",
    "    \"variable_assigned_value\" => true,\n",
    "    \"variable_is_bound\" => true,\n",
    "    \"values_raw\" => true\n",
    ")\n",
    "SR_heterogeneous = SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization,SeaPearl.HeterogeneousTrajectoryState}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Neural Network\n",
    "\n",
    "In the next cell, we will define the neural network used by the RL agent. We will be using Graph Neural Networks (GNNs) as the learnable architecture. The inputs will be graphs as defined earlier. The features are defined in a Dict and contain elements coming from the problem instance.\n",
    "\n",
    "## The GNN model\n",
    "\n",
    "The model used in this example is drawn from [Marty et al. 2023](https://arxiv.org/abs/2301.01913). The model is defined as a heterogeneous GNN, meaning that every node type uses a specific convolution. The model is comprised of the following elements:\n",
    "\n",
    "### GNN encoder\n",
    "The update equations are given by the following:\n",
    "\\begin{align*}\n",
    "h_{x}^{k+1} &= g\\left(\\theta_{1}^{k}h_{x}^{0} || \\theta_{2}^{k}h_{x}^{k} || \\oplus_{c\\in N_{c}(x)}\\theta_{3}^{k}h_{c}^{k} || \\oplus_{v\\in N_{v}(x)}\\theta_{4}^{k}h_{v}^{k}\\right) \\quad &\\forall x \\in V_1 \\\\\n",
    "h_{c}^{k+1} &= g\\left(\\theta_{5}^{k}h_{c}^{0} || \\theta_{6}^{k}h_{c}^{k} || \\oplus_{x\\in N_{x}(c)}\\theta_{7}^{k}h_{x}^{k}\\right) \\quad &\\forall c \\in V_2 \\\\\n",
    "h_{v}^{k+1} &= g\\left(\\theta_{8}^{k}h_{v}^{0} || \\theta_{9}^{k}h_{v}^{k} || \\oplus_{x\\in N_{x}(v)}\\theta_{10}^{k}h_{x}^{k}\\right) \\quad &\\forall v \\in V_3\n",
    "\\end{align*}\n",
    "\n",
    "- $h_{x}^{k}$, $h_{c}^{k}$, $h_{v}^{k}$ are the feature vectors for nodes of type variable, constraint, and value at layer $k$ respectively.\n",
    "- $h_{x}^{0}$, $h_{c}^{0}$, $h_{v}^{0}$ are the feature vectors for nodes of type variable, constraint, and value from the previous layer. They represent the skip-connections.\n",
    "- $g$ is the leakyReLU activation function which introduces non-linearity into the model.\n",
    "- $\\oplus$ is the mean aggregation function.\n",
    "- $||$ is the concatenation operator.\n",
    "- $\\theta_{i}^{k}$ are weight matrices at layer $k$ which are learned during training.\n",
    "- $N_{c}$, $N_{v}$ and $N_{x}$ are the sets of neighboring nodes for each node.\n",
    "\n",
    "### The action decoder\n",
    "Actions are selected using an epsilon-greedy policy. The Q-values are computed like this:\n",
    "\n",
    "$$\\widehat Q(h_{x}^{K}, h_{v}^{K}) = \\phi_{q}(\\phi_{x}(h_{x}^{K}) \\oplus \\phi_{v}(h_{v}^{K})) \\quad \\forall v \\in V_{x}$$\n",
    "\n",
    "- $h_{x}^{K}$ and $h_{v}^{K}$ are the final node embeddings for the variable and value nodes, respectively, after $K$ iterations in the GNN.\n",
    "- $\\phi_{x}$ and $\\phi_{v}$ are fully connected neural networks that take as input the embeddings of the variable and value nodes, respectively. They further transform these embeddings into an intermediate representation.\n",
    "- $\\oplus$ denotes concatenation of vectors.\n",
    "- $\\phi_{q}$ is another fully connected neural network that takes the concatenated vector as input and outputs a single scalar value, the Q-value.\n",
    "- $V_{x}$ is the subset of value nodes that can be assigned to variable $x$.\n",
    "\n",
    "\n",
    "### Visual Representation\n",
    " \n",
    "Putting it all together, we get the following model:\n",
    "\n",
    "<img src=\"img/High-level-architecture.png\" alt=\"Architecture\" style=\"width:900px; height:300px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_model (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Struct that holds the layers of the neural network\"\"\"\n",
    "struct HeterogeneousModel{A,B}\n",
    "    Inputlayer::A\n",
    "    Middlelayers::Vector{B}\n",
    "end\n",
    "\n",
    "Flux.@functor HeterogeneousModel # To allow automatic differentiation\n",
    "\"\"\"Passes feature graphs (instances) through the neural network, by always passing the original feature graph\n",
    "as well as the current feature graph to the layers of the network. \n",
    "\"\"\"\n",
    "function (m::HeterogeneousModel)(fg)\n",
    "    original_fg = deepcopy(fg)\n",
    "    out = m.Inputlayer(fg)\n",
    "    for layer in m.Middlelayers\n",
    "        out = layer(out, original_fg)\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "# The size of the input features for each type of node (variable, constraint, value), respectively\n",
    "feature_size = [6, 5, 2]\n",
    "\n",
    "\"\"\"\n",
    "    get_dense_chain(in, mid, out, n_layers, σ=Flux.identity; init=Flux.glorot_uniform)\n",
    "\n",
    "Create a chain of dense layers for a neural network.\n",
    "\n",
    "# Arguments\n",
    "- `in::Int`: The size of the input layer.\n",
    "- `mid::Int`: The size of the intermediate layers.\n",
    "- `out::Int`: The size of the output layer.\n",
    "- `n_layers::Int`: The number of layers in the chain.\n",
    "- `σ::Function=Flux.identity`: The activation function to use.\n",
    "- `init::Function=Flux.glorot_uniform`: The initialization method to use.\n",
    "\n",
    "# Returns\n",
    "A `Flux.Chain` object representing the chain of dense layers.\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "julia> get_dense_chain(10, 20, 5, 3)\n",
    "Chain(Dense(10, 20, σ), Dense(20, 20, σ), Dense(20, 5))\n",
    "```\n",
    "\"\"\"\n",
    "function get_dense_chain(in, mid, out, n_layers, σ=Flux.identity; init=Flux.glorot_uniform)\n",
    "    @assert n_layers >= 1\n",
    "    layers = []\n",
    "    if n_layers == 1\n",
    "        push!(layers, Flux.Dense(in, out, init=init))\n",
    "    elseif n_layers == 2\n",
    "        push!(layers, Flux.Dense(in, mid, σ, init=init))\n",
    "        push!(layers, Flux.Dense(mid, out, init=init))\n",
    "    else\n",
    "        push!(layers, Flux.Dense(in, mid, σ, init=init))\n",
    "        for i in 2:(n_layers-1)\n",
    "            push!(layers, Flux.Dense(mid, mid, σ, init=init))\n",
    "        end\n",
    "        push!(layers, Flux.Dense(mid, out, init=init))\n",
    "    end\n",
    "    return Flux.Chain(layers...)\n",
    "end\n",
    "\n",
    "# Builds the SeaPearl HeterogeneousFullFeaturedCPNN model\n",
    "function build_model(; \n",
    "        feature_size,\n",
    "        conv_size=8,\n",
    "        dense_size=16,\n",
    "        output_size=1,\n",
    "        n_layers_graph=3,\n",
    "        n_layers_node=2,\n",
    "        n_layers_output=2,\n",
    "        pool=SeaPearl.meanPooling(),\n",
    "        σ=Flux.leakyrelu,\n",
    "        init=Flux.glorot_uniform,\n",
    "        device=cpu\n",
    "    )\n",
    "    input_layer = SeaPearl.HeterogeneousGraphConvInit(feature_size, conv_size, σ, init=init) # input layer\n",
    "    middle_layers = SeaPearl.HeterogeneousGraphConv[] # middle layers\n",
    "    for i in 1:n_layers_graph-1\n",
    "        push!(middle_layers, SeaPearl.HeterogeneousGraphConv(conv_size => conv_size, feature_size, σ, pool=pool, init=init))\n",
    "    end\n",
    "    output_layer = SeaPearl.HeterogeneousGraphConv(conv_size => output_size, feature_size, σ, pool=pool, init=init) # output layer\n",
    "    dense_layers = get_dense_chain(conv_size, dense_size, dense_size, n_layers_node, σ, init=init) # dense layers\n",
    "    # Define the final output layer\n",
    "    final_output_layer = get_dense_chain(2 * dense_size, dense_size, output_size, n_layers_output, σ, init=init)\n",
    "\n",
    "    # Build the model\n",
    "    model = SeaPearl.HeterogeneousFullFeaturedCPNN(\n",
    "        HeterogeneousModel(input_layer, middle_layers),\n",
    "        dense_layers,\n",
    "        Flux.Chain(),\n",
    "        final_output_layer\n",
    "    ) |> device\n",
    "\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent, Replay Buffer and Exploration Policy\n",
    "\n",
    "We now have:\n",
    "- The reward function\n",
    "- An instance generator\n",
    "- A GNN\n",
    "- And all the settings we need!\n",
    "\n",
    "We now need to define:\n",
    "- The way we will store trajectories will be stored (in a circular buffer)\n",
    "- The exploration policy (eps-greedy)\n",
    "- The agent (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_epsilon_greedy_explorer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_heterogeneous_slart_trajectory(; capacity, n_actions)\n",
    "\n",
    "Create a circular buffer for storing trajectories in the context of reinforcement learning where not all actions are legal. \n",
    "SLART stands for State, Legal Actions, Reward, Terminal.\n",
    "\n",
    "# Arguments\n",
    "- `capacity::Int`: The maximum number of trajectories that can be stored in the buffer.\n",
    "- `n_actions::Int`: The number of possible actions that can be taken at each time step.\n",
    "\n",
    "# Returns\n",
    "A `CircularArraySLARTTrajectory` object with the specified capacity and legal actions mask, and an empty state buffer.\n",
    "\"\"\"\n",
    "function get_heterogeneous_slart_trajectory(; capacity, n_actions)\n",
    "    return RL.CircularArraySLARTTrajectory(\n",
    "        capacity=capacity,\n",
    "        state=SeaPearl.HeterogeneousTrajectoryState[] => (),\n",
    "        legal_actions_mask=Vector{Bool} => (n_actions,),\n",
    "    )\n",
    "end\n",
    "\n",
    "\"\"\"Builds the DQN agent for the heterogeneous model\"\"\"\n",
    "function get_heterogeneous_agent(; get_explorer, batch_size=16, update_horizon, min_replay_history, update_freq=1, target_update_freq=200, γ=0.999f0, get_heterogeneous_trajectory, get_heterogeneous_nn)\n",
    "    return RL.Agent(\n",
    "        policy=RL.QBasedPolicy(\n",
    "            learner=get_heterogeneous_learner(batch_size, update_horizon, min_replay_history, update_freq, target_update_freq, get_heterogeneous_nn, γ),\n",
    "            explorer=get_explorer(),\n",
    "        ),\n",
    "        trajectory=get_heterogeneous_trajectory()\n",
    "    )\n",
    "end\n",
    "\n",
    "\"\"\"Builds the learning part of the DQN agent\"\"\"\n",
    "function get_heterogeneous_learner(batch_size, update_horizon, min_replay_history, update_freq, target_update_freq, get_heterogeneous_nn, γ)\n",
    "    return RL.DQNLearner(\n",
    "        approximator=RL.NeuralNetworkApproximator(\n",
    "            model=get_heterogeneous_nn(),\n",
    "            optimizer=ADAM()\n",
    "        ),\n",
    "        target_approximator=RL.NeuralNetworkApproximator(\n",
    "            model=get_heterogeneous_nn(),\n",
    "            optimizer=ADAM()\n",
    "        ),\n",
    "        loss_func=Flux.Losses.huber_loss,\n",
    "        batch_size=batch_size,\n",
    "        update_horizon=update_horizon,\n",
    "        min_replay_history=min_replay_history,\n",
    "        update_freq=update_freq,\n",
    "        target_update_freq=target_update_freq,\n",
    "        γ=γ\n",
    "    )\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    get_epsilon_greedy_explorer(decay_steps, ϵ_stable; rng=nothing)\n",
    "\n",
    "Create an epsilon-greedy explorer for use in reinforcement learning.\n",
    "\n",
    "# Arguments\n",
    "- `decay_steps::Int`: The number of steps over which to decay the exploration rate.\n",
    "- `ϵ_stable::Real`: The minimum exploration rate to use after decay.\n",
    "- `rng::AbstractRNG`: (optional) A random number generator to use for sampling actions.\n",
    "\n",
    "# Returns\n",
    "An `EpsilonGreedyExplorer` object with the specified exploration rate decay and random number generator.\n",
    "\"\"\"\n",
    "function get_epsilon_greedy_explorer(decay_steps, ϵ_stable; rng=nothing)\n",
    "    if isnothing(rng)\n",
    "        return RL.EpsilonGreedyExplorer(\n",
    "            ϵ_stable=ϵ_stable,\n",
    "            kind=:exp,\n",
    "            decay_steps=decay_steps,\n",
    "            step=1\n",
    "        )\n",
    "    else\n",
    "        return RL.EpsilonGreedyExplorer(\n",
    "            ϵ_stable=ϵ_stable,\n",
    "            kind=:exp,\n",
    "            decay_steps=decay_steps,\n",
    "            step=1,\n",
    "            rng=rng\n",
    "        )\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent definition\n",
    "\n",
    "The agent and the related learned heuristic are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(Agent)\n",
       "├─ policy => typename(QBasedPolicy)\n",
       "│  ├─ learner => typename(DQNLearner)\n",
       "│  │  ├─ approximator => typename(NeuralNetworkApproximator)\n",
       "│  │  │  ├─ model => typename(SeaPearl.HeterogeneousFullFeaturedCPNN)\n",
       "│  │  │  │  ├─ graphChain => typename(HeterogeneousModel)\n",
       "│  │  │  │  │  ├─ Inputlayer => typename(SeaPearl.HeterogeneousGraphConvInit)\n",
       "│  │  │  │  │  │  ├─ weightsvar => 8×6 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightscon => 8×5 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightsval => 8×2 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ biasvar => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biascon => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biasval => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │  └─ Middlelayers => 2-element Vector{SeaPearl.HeterogeneousGraphConv{Matrix{Float32}, Vector{Float32}, SeaPearl.meanPooling}}\n",
       "│  │  │  │  ├─ varChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ valChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ globalChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  └─ outputChain => typename(Chain)\n",
       "│  │  │  │     └─ layers\n",
       "│  │  │  │        ├─ 1\n",
       "│  │  │  │        │  └─ typename(Dense)\n",
       "│  │  │  │        │     ├─ weight => 16×32 Matrix{Float32}\n",
       "│  │  │  │        │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │        │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │        └─ 2\n",
       "│  │  │  │           └─ typename(Dense)\n",
       "│  │  │  │              ├─ weight => 1×16 Matrix{Float32}\n",
       "│  │  │  │              ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │              └─ σ => typename(typeof(identity))\n",
       "│  │  │  └─ optimizer => typename(ADAM)\n",
       "│  │  │     ├─ eta => 0.001\n",
       "│  │  │     ├─ beta\n",
       "│  │  │     │  ├─ 1\n",
       "│  │  │     │  │  └─ 0.9\n",
       "│  │  │     │  └─ 2\n",
       "│  │  │     │     └─ 0.999\n",
       "│  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ target_approximator => typename(NeuralNetworkApproximator)\n",
       "│  │  │  ├─ model => typename(SeaPearl.HeterogeneousFullFeaturedCPNN)\n",
       "│  │  │  │  ├─ graphChain => typename(HeterogeneousModel)\n",
       "│  │  │  │  │  ├─ Inputlayer => typename(SeaPearl.HeterogeneousGraphConvInit)\n",
       "│  │  │  │  │  │  ├─ weightsvar => 8×6 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightscon => 8×5 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightsval => 8×2 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ biasvar => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biascon => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biasval => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │  └─ Middlelayers => 2-element Vector{SeaPearl.HeterogeneousGraphConv{Matrix{Float32}, Vector{Float32}, SeaPearl.meanPooling}}\n",
       "│  │  │  │  ├─ varChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ valChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ globalChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  └─ outputChain => typename(Chain)\n",
       "│  │  │  │     └─ layers\n",
       "│  │  │  │        ├─ 1\n",
       "│  │  │  │        │  └─ typename(Dense)\n",
       "│  │  │  │        │     ├─ weight => 16×32 Matrix{Float32}\n",
       "│  │  │  │        │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │        │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │        └─ 2\n",
       "│  │  │  │           └─ typename(Dense)\n",
       "│  │  │  │              ├─ weight => 1×16 Matrix{Float32}\n",
       "│  │  │  │              ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │              └─ σ => typename(typeof(identity))\n",
       "│  │  │  └─ optimizer => typename(ADAM)\n",
       "│  │  │     ├─ eta => 0.001\n",
       "│  │  │     ├─ beta\n",
       "│  │  │     │  ├─ 1\n",
       "│  │  │     │  │  └─ 0.9\n",
       "│  │  │     │  └─ 2\n",
       "│  │  │     │     └─ 0.999\n",
       "│  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ loss_func => typename(typeof(Flux.Losses.huber_loss))\n",
       "│  │  ├─ min_replay_history => 56\n",
       "│  │  ├─ update_freq => 1\n",
       "│  │  ├─ update_step => 0\n",
       "│  │  ├─ target_update_freq => 20\n",
       "│  │  ├─ sampler => typename(NStepBatchSampler)\n",
       "│  │  │  ├─ γ => 0.99\n",
       "│  │  │  ├─ n => 4\n",
       "│  │  │  ├─ batch_size => 64\n",
       "│  │  │  ├─ stack_size => typename(Nothing)\n",
       "│  │  │  ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "│  │  │  └─ cache => typename(Nothing)\n",
       "│  │  ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "│  │  ├─ loss => 0.0\n",
       "│  │  └─ is_enable_double_DQN => true\n",
       "│  └─ explorer => typename(EpsilonGreedyExplorer)\n",
       "│     ├─ ϵ_stable => 0.01\n",
       "│     ├─ ϵ_init => 1.0\n",
       "│     ├─ warmup_steps => 0\n",
       "│     ├─ decay_steps => 1050\n",
       "│     ├─ step => 1\n",
       "│     ├─ rng => typename(MersenneTwister)\n",
       "│     └─ is_training => true\n",
       "└─ trajectory => typename(Trajectory)\n",
       "   └─ traces => typename(NamedTuple)\n",
       "      ├─ state => 0-element CircularArrayBuffers.CircularVectorBuffer{SeaPearl.HeterogeneousTrajectoryState, Vector{SeaPearl.HeterogeneousTrajectoryState}}\n",
       "      ├─ legal_actions_mask => 2×0 CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}\n",
       "      ├─ action => 0-element CircularArrayBuffers.CircularVectorBuffer{Int64, Vector{Int64}}\n",
       "      ├─ reward => 0-element CircularArrayBuffers.CircularVectorBuffer{Float32, Vector{Float32}}\n",
       "      └─ terminal => 0-element CircularArrayBuffers.CircularVectorBuffer{Bool, Vector{Bool}}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = SeaPearl.meanPooling()\n",
    "\n",
    "agent = get_heterogeneous_agent(;\n",
    "    get_heterogeneous_trajectory=() -> get_heterogeneous_slart_trajectory(capacity=agent_config.trajectory_capacity, n_actions=2),\n",
    "    get_explorer=() -> get_epsilon_greedy_explorer(decay_steps_explorer, 0.01; rng=rngExp),\n",
    "    batch_size=agent_config.batch_size,\n",
    "    update_horizon=update_horizon,\n",
    "    min_replay_history=Int(round(16 * n_step_per_episode // 2)),\n",
    "    update_freq=agent_config.update_freq,\n",
    "    target_update_freq=agent_config.target_update_freq,\n",
    "    get_heterogeneous_nn=() -> build_model(\n",
    "        feature_size=feature_size,\n",
    "        conv_size=8,\n",
    "        dense_size=16,\n",
    "        output_size=1,\n",
    "        n_layers_graph=3,\n",
    "        n_layers_node=3,\n",
    "        n_layers_output=2,\n",
    "        pool=pool,\n",
    "        σ=NNlib.leakyrelu,\n",
    "        init=init,\n",
    "        device=device\n",
    "    ),\n",
    "    γ=0.99f0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up comparisons and running the experiment\n",
    "\n",
    "We now have everything we need to run the experiment. We will run the experiment for 1000 episodes and compare the performance of value selection heuristics:\n",
    "- The learned heuristic\n",
    "- A random agent \n",
    "- Heuristic that always selects the max value available.\n",
    "\n",
    "The agent has already been defined; let's define the other two heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{SeaPearl.ValueSelection}:\n",
       " SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput}(typename(Agent)\n",
       "├─ policy => typename(QBasedPolicy)\n",
       "│  ├─ learner => typename(DQNLearner)\n",
       "│  │  ├─ approximator => typename(NeuralNetworkApproximator)\n",
       "│  │  │  ├─ model => typename(SeaPearl.HeterogeneousFullFeaturedCPNN)\n",
       "│  │  │  │  ├─ graphChain => typename(HeterogeneousModel)\n",
       "│  │  │  │  │  ├─ Inputlayer => typename(SeaPearl.HeterogeneousGraphConvInit)\n",
       "│  │  │  │  │  │  ├─ weightsvar => 8×6 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightscon => 8×5 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightsval => 8×2 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ biasvar => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biascon => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biasval => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │  └─ Middlelayers => 2-element Vector{SeaPearl.HeterogeneousGraphConv{Matrix{Float32}, Vector{Float32}, SeaPearl.meanPooling}}\n",
       "│  │  │  │  ├─ varChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ valChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ globalChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  └─ outputChain => typename(Chain)\n",
       "│  │  │  │     └─ layers\n",
       "│  │  │  │        ├─ 1\n",
       "│  │  │  │        │  └─ typename(Dense)\n",
       "│  │  │  │        │     ├─ weight => 16×32 Matrix{Float32}\n",
       "│  │  │  │        │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │        │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │        └─ 2\n",
       "│  │  │  │           └─ typename(Dense)\n",
       "│  │  │  │              ├─ weight => 1×16 Matrix{Float32}\n",
       "│  │  │  │              ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │              └─ σ => typename(typeof(identity))\n",
       "│  │  │  └─ optimizer => typename(ADAM)\n",
       "│  │  │     ├─ eta => 0.001\n",
       "│  │  │     ├─ beta\n",
       "│  │  │     │  ├─ 1\n",
       "│  │  │     │  │  └─ 0.9\n",
       "│  │  │     │  └─ 2\n",
       "│  │  │     │     └─ 0.999\n",
       "│  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ target_approximator => typename(NeuralNetworkApproximator)\n",
       "│  │  │  ├─ model => typename(SeaPearl.HeterogeneousFullFeaturedCPNN)\n",
       "│  │  │  │  ├─ graphChain => typename(HeterogeneousModel)\n",
       "│  │  │  │  │  ├─ Inputlayer => typename(SeaPearl.HeterogeneousGraphConvInit)\n",
       "│  │  │  │  │  │  ├─ weightsvar => 8×6 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightscon => 8×5 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ weightsval => 8×2 Matrix{Float32}\n",
       "│  │  │  │  │  │  ├─ biasvar => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biascon => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  ├─ biasval => 8-element Vector{Float32}\n",
       "│  │  │  │  │  │  └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │  └─ Middlelayers => 2-element Vector{SeaPearl.HeterogeneousGraphConv{Matrix{Float32}, Vector{Float32}, SeaPearl.meanPooling}}\n",
       "│  │  │  │  ├─ varChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ valChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×8 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 16×16 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  ├─ globalChain => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  └─ outputChain => typename(Chain)\n",
       "│  │  │  │     └─ layers\n",
       "│  │  │  │        ├─ 1\n",
       "│  │  │  │        │  └─ typename(Dense)\n",
       "│  │  │  │        │     ├─ weight => 16×32 Matrix{Float32}\n",
       "│  │  │  │        │     ├─ bias => 16-element Vector{Float32}\n",
       "│  │  │  │        │     └─ σ => typename(typeof(leakyrelu))\n",
       "│  │  │  │        └─ 2\n",
       "│  │  │  │           └─ typename(Dense)\n",
       "│  │  │  │              ├─ weight => 1×16 Matrix{Float32}\n",
       "│  │  │  │              ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │              └─ σ => typename(typeof(identity))\n",
       "│  │  │  └─ optimizer => typename(ADAM)\n",
       "│  │  │     ├─ eta => 0.001\n",
       "│  │  │     ├─ beta\n",
       "│  │  │     │  ├─ 1\n",
       "│  │  │     │  │  └─ 0.9\n",
       "│  │  │     │  └─ 2\n",
       "│  │  │     │     └─ 0.999\n",
       "│  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ loss_func => typename(typeof(Flux.Losses.huber_loss))\n",
       "│  │  ├─ min_replay_history => 56\n",
       "│  │  ├─ update_freq => 1\n",
       "│  │  ├─ update_step => 0\n",
       "│  │  ├─ target_update_freq => 20\n",
       "│  │  ├─ sampler => typename(NStepBatchSampler)\n",
       "│  │  │  ├─ γ => 0.99\n",
       "│  │  │  ├─ n => 4\n",
       "│  │  │  ├─ batch_size => 64\n",
       "│  │  │  ├─ stack_size => typename(Nothing)\n",
       "│  │  │  ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "│  │  │  └─ cache => typename(Nothing)\n",
       "│  │  ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "│  │  ├─ loss => 0.0\n",
       "│  │  └─ is_enable_double_DQN => true\n",
       "│  └─ explorer => typename(EpsilonGreedyExplorer)\n",
       "│     ├─ ϵ_stable => 0.01\n",
       "│     ├─ ϵ_init => 1.0\n",
       "│     ├─ warmup_steps => 0\n",
       "│     ├─ decay_steps => 1050\n",
       "│     ├─ step => 1\n",
       "│     ├─ rng => typename(MersenneTwister)\n",
       "│     └─ is_training => true\n",
       "└─ trajectory => typename(Trajectory)\n",
       "   └─ traces => typename(NamedTuple)\n",
       "      ├─ state => 0-element CircularArrayBuffers.CircularVectorBuffer{SeaPearl.HeterogeneousTrajectoryState, Vector{SeaPearl.HeterogeneousTrajectoryState}}\n",
       "      ├─ legal_actions_mask => 2×0 CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}\n",
       "      ├─ action => 0-element CircularArrayBuffers.CircularVectorBuffer{Int64, Vector{Int64}}\n",
       "      ├─ reward => 0-element CircularArrayBuffers.CircularVectorBuffer{Float32, Vector{Float32}}\n",
       "      └─ terminal => 0-element CircularArrayBuffers.CircularVectorBuffer{Bool, Vector{Bool}}\n",
       ", nothing, nothing, nothing, nothing, nothing, nothing, false, true, Dict{String, Bool}(\"variable_initial_domain_size\" => 1, \"values_raw\" => 1, \"constraint_type\" => 1, \"variable_is_bound\" => 1, \"nb_not_bounded_variable\" => 1, \"variable_assigned_value\" => 1, \"node_number_of_neighbors\" => 1, \"variable_is_objective\" => 1, \"variable_domain_size\" => 1, \"constraint_activity\" => 1…))\n",
       " SeaPearl.BasicHeuristic(selectMax, nothing)\n",
       " SeaPearl.BasicHeuristic(select_random_value, nothing)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Selects the maximum value from the domain of a variable\"\"\"\n",
    "selectMax(x::SeaPearl.IntVar; cpmodel=nothing) = SeaPearl.maximum(x.domain)\n",
    "\n",
    "\"\"\"Selects a random value from the domain of a variable\"\"\"\n",
    "function select_random_value(x::SeaPearl.IntVar; cpmodel=nothing)\n",
    "    selected_number = rand(1:length(x.domain))\n",
    "    i = 1\n",
    "    for value in x.domain\n",
    "        if i == selected_number\n",
    "            return value\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "    @assert false \"This should not happen\"\n",
    "end\n",
    "\n",
    "randomHeuristics = []\n",
    "for i in 1:mis_settings.nbRandomHeuristics\n",
    "    push!(randomHeuristics, SeaPearl.BasicHeuristic(select_random_value))\n",
    "end\n",
    "\n",
    "heuristic_max = SeaPearl.BasicHeuristic(selectMax)\n",
    "learned_heuristic = SeaPearl.SimpleLearnedHeuristic{SR_heterogeneous,reward,SeaPearl.FixedOutput}(agent; chosen_features=chosen_features)\n",
    "valueSelectionArray = [learned_heuristic, heuristic_max]\n",
    "append!(valueSelectionArray, randomHeuristics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection heuristic\n",
    "\n",
    "For all experiments, we will be using the minimum domain heuristic variable selection heuristic. This heuristic selects the variable with the smallest domain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeaPearl.MinDomainVariableSelection{false}()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variableSelection = SeaPearl.MinDomainVariableSelection{false}()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem\n",
    "\n",
    "Let's finally solve the problem. The following cell will train a DQN agent on MIS instances and evaluate its performance on the same instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning_mis (generic function with 2 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricsArray, eval_metricsArray = SeaPearl.train!(\n",
    "    valueSelectionArray=valueSelectionArray,\n",
    "    generator=instance_generator,\n",
    "    nbEpisodes=mis_settings.nbEpisodes,\n",
    "    strategy=SeaPearl.DFSearch(),\n",
    "    variableHeuristic=variableSelection,\n",
    "    out_solver=true,\n",
    "    verbose=false,\n",
    "    evaluator=SeaPearl.SameInstancesEvaluator(valueSelectionArray, instance_generator; evalFreq=mis_settings.evalFreq, nbInstances=mis_settings.nbInstances),\n",
    "    restartPerInstances=mis_settings.restartPerInstances\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n",
    "\n",
    "Now that we have a small trained model, let's look at the results. First, we will have a look at the performance of the learned heuristic vs random and select max heuristic over the course of the training. Then, we will compare their performance on unseen instances of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benchmark (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility functions fetch and organize training metrics + plotting & benchmarking\n",
    "include(\"../../../learning_cp/utils/save_metrics.jl\")\n",
    "include(\"../../../learning_cp/utils/plot_metrics.jl\")\n",
    "include(\"../../../learning_cp/utils/benchmark.jl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training performance\n",
    "\n",
    "In this section, we will be comparing the performance of the learned heuristic with the random and select max heuristics. We will be looking at the performance of the heuristics over the course of the training. The plot in the next cell represents the optimum obtained by the heuristics at every evaluation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = get_metrics_dataframe(eval_metricsArray)\n",
    "plot_first_solution(training_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on unseen instances\n",
    "\n",
    "Next up, we will compare the performances of the heuristics on unseen instances. In this section, you are free to play with the various parameters and see their effect. The plot in this section represents the optimum obtained by the heuristics for the first solution they find. For small instances, you should see that the learned heuristic learns something close to the select max heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with strategy : SeaPearl.DFSearch()\n",
      "Switching to agent : SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput}SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0045579s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0040525s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0040592s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0039327s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.004113s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0043162s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 11 nodes, taken 0.0038754s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0045169s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0044804s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0052082s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0047853s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0047458s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0050452s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 15 nodes, taken 0.0051911s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0049785s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.00457s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0044077s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0049568s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0068274s, number of solutions found : 1\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 13 nodes, taken 0.0055783s, number of solutions found : 1\n",
      "Switching to agent : SeaPearl.BasicHeuristicSeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0015527s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012091s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012108s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012764s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0011689s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0016363s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 11 nodes, taken 0.0012464s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012802s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0010217s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0013587s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0011754s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012254s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012302s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0012809s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012185s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0010514s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0011029s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0011969s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.001941s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0014624s, number of solutions found : 1\n",
      "Switching to agent : SeaPearl.BasicHeuristicSeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0015088s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0015996s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.001653s, number of solutions found : 3\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0013167s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 17 nodes, taken 0.0017053s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 17 nodes, taken 0.0016626s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0012747s, number of solutions found : 3\n",
      "SeaPearl.BasicHeuristic evaluated with: 17 nodes, taken 0.0017622s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0014109s, number of solutions found : 3\n",
      "SeaPearl.BasicHeuristic evaluated with: 17 nodes, taken 0.0019446s, number of solutions found : 3\n",
      "SeaPearl.BasicHeuristic evaluated with: 19 nodes, taken 0.001857s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 17 nodes, taken 0.0033081s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 13 nodes, taken 0.0027539s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.001404s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0016435s, number of solutions found : 3\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0016782s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0014731s, number of solutions found : 1\n",
      "SeaPearl.BasicHeuristic evaluated with: 23 nodes, taken 0.0022939s, number of solutions found : 4\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0014735s, number of solutions found : 2\n",
      "SeaPearl.BasicHeuristic evaluated with: 15 nodes, taken 0.0017158s, number of solutions found : 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>60 rows × 11 columns (omitted printing of 6 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>num_heuristic</th><th>num_instance</th><th>num_experiment</th><th>heuristic_type</th><th>reward_type</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"String\">String</th><th title=\"Union{Nothing, SubString{String}}\">Union…</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>2</th><td>1</td><td>2</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>3</th><td>1</td><td>3</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>4</th><td>1</td><td>4</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>5</th><td>1</td><td>5</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>6</th><td>1</td><td>6</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>7</th><td>1</td><td>7</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>8</th><td>1</td><td>8</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>9</th><td>1</td><td>9</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>10</th><td>1</td><td>10</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>11</th><td>1</td><td>11</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>12</th><td>1</td><td>12</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>13</th><td>1</td><td>13</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>14</th><td>1</td><td>14</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>15</th><td>1</td><td>15</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>16</th><td>1</td><td>16</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>17</th><td>1</td><td>17</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>18</th><td>1</td><td>18</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>19</th><td>1</td><td>19</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>20</th><td>1</td><td>20</td><td>1</td><td>SimpleLearnedHeuristic</td><td>GeneralReward</td></tr><tr><th>21</th><td>2</td><td>1</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>22</th><td>2</td><td>2</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>23</th><td>2</td><td>3</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>24</th><td>2</td><td>4</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>25</th><td>2</td><td>5</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>26</th><td>2</td><td>6</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>27</th><td>2</td><td>7</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>28</th><td>2</td><td>8</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>29</th><td>2</td><td>9</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>30</th><td>2</td><td>10</td><td>1</td><td>BasicHeuristic(selectMax)</td><td></td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& num\\_heuristic & num\\_instance & num\\_experiment & heuristic\\_type & reward\\_type & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & String & Union… & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t2 & 1 & 2 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t3 & 1 & 3 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t4 & 1 & 4 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t5 & 1 & 5 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t6 & 1 & 6 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t7 & 1 & 7 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t8 & 1 & 8 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t9 & 1 & 9 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t10 & 1 & 10 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t11 & 1 & 11 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t12 & 1 & 12 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t13 & 1 & 13 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t14 & 1 & 14 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t15 & 1 & 15 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t16 & 1 & 16 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t17 & 1 & 17 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t18 & 1 & 18 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t19 & 1 & 19 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t20 & 1 & 20 & 1 & SimpleLearnedHeuristic & GeneralReward & $\\dots$ \\\\\n",
       "\t21 & 2 & 1 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t22 & 2 & 2 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t23 & 2 & 3 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t24 & 2 & 4 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t25 & 2 & 5 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t26 & 2 & 6 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t27 & 2 & 7 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t28 & 2 & 8 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t29 & 2 & 9 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t30 & 2 & 10 & 1 & BasicHeuristic(selectMax) &  & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m60×11 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m num_heuristic \u001b[0m\u001b[1m num_instance \u001b[0m\u001b[1m num_experiment \u001b[0m\u001b[1m heuristic_type            \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64         \u001b[0m\u001b[90m Int64        \u001b[0m\u001b[90m Int64          \u001b[0m\u001b[90m String                    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │             1             1               1  SimpleLearnedHeuristic     ⋯\n",
       "   2 │             1             2               1  SimpleLearnedHeuristic\n",
       "   3 │             1             3               1  SimpleLearnedHeuristic\n",
       "   4 │             1             4               1  SimpleLearnedHeuristic\n",
       "   5 │             1             5               1  SimpleLearnedHeuristic     ⋯\n",
       "   6 │             1             6               1  SimpleLearnedHeuristic\n",
       "   7 │             1             7               1  SimpleLearnedHeuristic\n",
       "   8 │             1             8               1  SimpleLearnedHeuristic\n",
       "   9 │             1             9               1  SimpleLearnedHeuristic     ⋯\n",
       "  10 │             1            10               1  SimpleLearnedHeuristic\n",
       "  11 │             1            11               1  SimpleLearnedHeuristic\n",
       "  ⋮  │       ⋮             ⋮              ⋮                         ⋮          ⋱\n",
       "  51 │             3            11               1  BasicHeuristic(select_rand\n",
       "  52 │             3            12               1  BasicHeuristic(select_rand ⋯\n",
       "  53 │             3            13               1  BasicHeuristic(select_rand\n",
       "  54 │             3            14               1  BasicHeuristic(select_rand\n",
       "  55 │             3            15               1  BasicHeuristic(select_rand\n",
       "  56 │             3            16               1  BasicHeuristic(select_rand ⋯\n",
       "  57 │             3            17               1  BasicHeuristic(select_rand\n",
       "  58 │             3            18               1  BasicHeuristic(select_rand\n",
       "  59 │             3            19               1  BasicHeuristic(select_rand\n",
       "  60 │             3            20               1  BasicHeuristic(select_rand ⋯\n",
       "\u001b[36m                                                   8 columns and 39 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, Plots\n",
    "\n",
    "validation_generator = SeaPearl.MaximumIndependentSetGenerator(8, 3)\n",
    "\n",
    "num_instances = 20 # Number of instances to evaluate on\n",
    "node_budget = 10000 # Budget of visited nodes\n",
    "take_objective = false # Set it to true if we have to branch on the object ive variable\n",
    "eval_strategy = SeaPearl.DFSearch() #\n",
    "include_dfs = true # Set it to true if you want to evaluate with DFS in addition to ILDS\n",
    "basicHeuristics = Dict()\n",
    "num_random_heuristics = 2\n",
    "\n",
    "for (i, random_heuristic) in enumerate(randomHeuristics)\n",
    "    push!(basicHeuristics, \"random\"*string(i) => random_heuristic)\n",
    "end\n",
    "\n",
    "push!(basicHeuristics, \"max\" => heuristic_max)\n",
    "evaluation_df = benchmark(\n",
    "    models=[agent.policy.learner.approximator], \n",
    "    evaluation_folder=pwd(),\n",
    "    num_instances=num_instances, \n",
    "    chosen_features=chosen_features,\n",
    "    take_objective=take_objective,\n",
    "    generator=validation_generator,\n",
    "    basicHeuristics=basicHeuristics,\n",
    "    save_experiment_metrics=false,\n",
    "    include_dfs=include_dfs, \n",
    "    budget=node_budget,\n",
    "    ILDS=eval_strategy\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing heuristics across 20 instances\n",
    "\n",
    "We will now compare the performance of the learned heuristic with the random and select max heuristics on 20 unseen instances of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip390\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip391\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M175.445 1423.18 L2352.76 1423.18 L2352.76 47.2441 L175.445 47.2441  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip392\">\n",
       "    <rect x=\"175\" y=\"47\" width=\"2178\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"237.067,1423.18 237.067,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"345.176,1423.18 345.176,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"453.285,1423.18 453.285,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"561.394,1423.18 561.394,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"669.502,1423.18 669.502,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"777.611,1423.18 777.611,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"885.72,1423.18 885.72,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"993.829,1423.18 993.829,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1101.94,1423.18 1101.94,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1210.05,1423.18 1210.05,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1318.15,1423.18 1318.15,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1426.26,1423.18 1426.26,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1534.37,1423.18 1534.37,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1642.48,1423.18 1642.48,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1750.59,1423.18 1750.59,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1858.7,1423.18 1858.7,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1966.81,1423.18 1966.81,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2074.92,1423.18 2074.92,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2183.03,1423.18 2183.03,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2291.13,1423.18 2291.13,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"175.445,1423.18 2352.76,1423.18 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"237.067,1423.18 237.067,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"345.176,1423.18 345.176,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"453.285,1423.18 453.285,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"561.394,1423.18 561.394,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"669.502,1423.18 669.502,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"777.611,1423.18 777.611,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"885.72,1423.18 885.72,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"993.829,1423.18 993.829,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1101.94,1423.18 1101.94,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1210.05,1423.18 1210.05,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1318.15,1423.18 1318.15,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1426.26,1423.18 1426.26,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1534.37,1423.18 1534.37,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1642.48,1423.18 1642.48,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1750.59,1423.18 1750.59,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1858.7,1423.18 1858.7,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1966.81,1423.18 1966.81,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2074.92,1423.18 2074.92,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2183.03,1423.18 2183.03,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2291.13,1423.18 2291.13,1404.28 \"/>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M227.449 1481.64 L235.088 1481.64 L235.088 1455.28 L226.778 1456.95 L226.778 1452.69 L235.042 1451.02 L239.718 1451.02 L239.718 1481.64 L247.357 1481.64 L247.357 1485.58 L227.449 1485.58 L227.449 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M339.829 1481.64 L356.148 1481.64 L356.148 1485.58 L334.204 1485.58 L334.204 1481.64 Q336.866 1478.89 341.449 1474.26 Q346.056 1469.61 347.236 1468.27 Q349.482 1465.74 350.361 1464.01 Q351.264 1462.25 351.264 1460.56 Q351.264 1457.8 349.319 1456.07 Q347.398 1454.33 344.296 1454.33 Q342.097 1454.33 339.644 1455.09 Q337.213 1455.86 334.435 1457.41 L334.435 1452.69 Q337.259 1451.55 339.713 1450.97 Q342.167 1450.39 344.204 1450.39 Q349.574 1450.39 352.769 1453.08 Q355.963 1455.77 355.963 1460.26 Q355.963 1462.39 355.153 1464.31 Q354.366 1466.2 352.259 1468.8 Q351.681 1469.47 348.579 1472.69 Q345.477 1475.88 339.829 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M457.532 1466.95 Q460.889 1467.66 462.764 1469.93 Q464.662 1472.2 464.662 1475.53 Q464.662 1480.65 461.144 1483.45 Q457.625 1486.25 451.144 1486.25 Q448.968 1486.25 446.653 1485.81 Q444.361 1485.39 441.908 1484.54 L441.908 1480.02 Q443.852 1481.16 446.167 1481.74 Q448.482 1482.32 451.005 1482.32 Q455.403 1482.32 457.694 1480.58 Q460.009 1478.84 460.009 1475.53 Q460.009 1472.48 457.856 1470.77 Q455.727 1469.03 451.907 1469.03 L447.88 1469.03 L447.88 1465.19 L452.093 1465.19 Q455.542 1465.19 457.37 1463.82 Q459.199 1462.43 459.199 1459.84 Q459.199 1457.18 457.301 1455.77 Q455.426 1454.33 451.907 1454.33 Q449.986 1454.33 447.787 1454.75 Q445.588 1455.16 442.949 1456.04 L442.949 1451.88 Q445.611 1451.14 447.926 1450.77 Q450.264 1450.39 452.324 1450.39 Q457.648 1450.39 460.75 1452.83 Q463.852 1455.23 463.852 1459.35 Q463.852 1462.22 462.208 1464.21 Q460.565 1466.18 457.532 1466.95 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M564.403 1455.09 L552.597 1473.54 L564.403 1473.54 L564.403 1455.09 M563.176 1451.02 L569.056 1451.02 L569.056 1473.54 L573.986 1473.54 L573.986 1477.43 L569.056 1477.43 L569.056 1485.58 L564.403 1485.58 L564.403 1477.43 L548.801 1477.43 L548.801 1472.92 L563.176 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M659.78 1451.02 L678.137 1451.02 L678.137 1454.96 L664.063 1454.96 L664.063 1463.43 Q665.081 1463.08 666.1 1462.92 Q667.118 1462.73 668.137 1462.73 Q673.924 1462.73 677.303 1465.9 Q680.683 1469.08 680.683 1474.49 Q680.683 1480.07 677.211 1483.17 Q673.738 1486.25 667.419 1486.25 Q665.243 1486.25 662.975 1485.88 Q660.729 1485.51 658.322 1484.77 L658.322 1480.07 Q660.405 1481.2 662.627 1481.76 Q664.85 1482.32 667.326 1482.32 Q671.331 1482.32 673.669 1480.21 Q676.007 1478.1 676.007 1474.49 Q676.007 1470.88 673.669 1468.77 Q671.331 1466.67 667.326 1466.67 Q665.451 1466.67 663.576 1467.08 Q661.725 1467.5 659.78 1468.38 L659.78 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M778.016 1466.44 Q774.868 1466.44 773.016 1468.59 Q771.187 1470.74 771.187 1474.49 Q771.187 1478.22 773.016 1480.39 Q774.868 1482.55 778.016 1482.55 Q781.164 1482.55 782.993 1480.39 Q784.845 1478.22 784.845 1474.49 Q784.845 1470.74 782.993 1468.59 Q781.164 1466.44 778.016 1466.44 M787.299 1451.78 L787.299 1456.04 Q785.539 1455.21 783.734 1454.77 Q781.951 1454.33 780.192 1454.33 Q775.562 1454.33 773.109 1457.45 Q770.678 1460.58 770.331 1466.9 Q771.697 1464.89 773.757 1463.82 Q775.817 1462.73 778.294 1462.73 Q783.502 1462.73 786.511 1465.9 Q789.544 1469.05 789.544 1474.49 Q789.544 1479.82 786.396 1483.03 Q783.248 1486.25 778.016 1486.25 Q772.021 1486.25 768.85 1481.67 Q765.678 1477.06 765.678 1468.33 Q765.678 1460.14 769.567 1455.28 Q773.456 1450.39 780.007 1450.39 Q781.766 1450.39 783.549 1450.74 Q785.354 1451.09 787.299 1451.78 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M874.609 1451.02 L896.831 1451.02 L896.831 1453.01 L884.285 1485.58 L879.4 1485.58 L891.206 1454.96 L874.609 1454.96 L874.609 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M993.829 1469.17 Q990.495 1469.17 988.574 1470.95 Q986.676 1472.73 986.676 1475.86 Q986.676 1478.98 988.574 1480.77 Q990.495 1482.55 993.829 1482.55 Q997.162 1482.55 999.083 1480.77 Q1001 1478.96 1001 1475.86 Q1001 1472.73 999.083 1470.95 Q997.185 1469.17 993.829 1469.17 M989.153 1467.18 Q986.143 1466.44 984.454 1464.38 Q982.787 1462.32 982.787 1459.35 Q982.787 1455.21 985.727 1452.8 Q988.69 1450.39 993.829 1450.39 Q998.991 1450.39 1001.93 1452.8 Q1004.87 1455.21 1004.87 1459.35 Q1004.87 1462.32 1003.18 1464.38 Q1001.51 1466.44 998.528 1467.18 Q1001.91 1467.96 1003.78 1470.26 Q1005.68 1472.55 1005.68 1475.86 Q1005.68 1480.88 1002.6 1483.57 Q999.546 1486.25 993.829 1486.25 Q988.111 1486.25 985.032 1483.57 Q981.977 1480.88 981.977 1475.86 Q981.977 1472.55 983.875 1470.26 Q985.773 1467.96 989.153 1467.18 M987.44 1459.79 Q987.44 1462.48 989.106 1463.98 Q990.796 1465.49 993.829 1465.49 Q996.838 1465.49 998.528 1463.98 Q1000.24 1462.48 1000.24 1459.79 Q1000.24 1457.11 998.528 1455.6 Q996.838 1454.1 993.829 1454.1 Q990.796 1454.1 989.106 1455.6 Q987.44 1457.11 987.44 1459.79 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1092.24 1484.86 L1092.24 1480.6 Q1094 1481.44 1095.8 1481.88 Q1097.61 1482.32 1099.34 1482.32 Q1103.97 1482.32 1106.4 1479.21 Q1108.86 1476.09 1109.21 1469.75 Q1107.86 1471.74 1105.8 1472.8 Q1103.74 1473.87 1101.24 1473.87 Q1096.06 1473.87 1093.03 1470.74 Q1090.02 1467.59 1090.02 1462.15 Q1090.02 1456.83 1093.16 1453.61 Q1096.31 1450.39 1101.54 1450.39 Q1107.54 1450.39 1110.69 1455 Q1113.86 1459.58 1113.86 1468.33 Q1113.86 1476.51 1109.97 1481.39 Q1106.1 1486.25 1099.55 1486.25 Q1097.79 1486.25 1095.99 1485.9 Q1094.18 1485.56 1092.24 1484.86 M1101.54 1470.21 Q1104.69 1470.21 1106.52 1468.06 Q1108.37 1465.9 1108.37 1462.15 Q1108.37 1458.43 1106.52 1456.27 Q1104.69 1454.1 1101.54 1454.1 Q1098.4 1454.1 1096.54 1456.27 Q1094.72 1458.43 1094.72 1462.15 Q1094.72 1465.9 1096.54 1468.06 Q1098.4 1470.21 1101.54 1470.21 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1184.73 1481.64 L1192.37 1481.64 L1192.37 1455.28 L1184.06 1456.95 L1184.06 1452.69 L1192.33 1451.02 L1197 1451.02 L1197 1481.64 L1204.64 1481.64 L1204.64 1485.58 L1184.73 1485.58 L1184.73 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1224.09 1454.1 Q1220.47 1454.1 1218.65 1457.66 Q1216.84 1461.2 1216.84 1468.33 Q1216.84 1475.44 1218.65 1479.01 Q1220.47 1482.55 1224.09 1482.55 Q1227.72 1482.55 1229.53 1479.01 Q1231.35 1475.44 1231.35 1468.33 Q1231.35 1461.2 1229.53 1457.66 Q1227.72 1454.1 1224.09 1454.1 M1224.09 1450.39 Q1229.9 1450.39 1232.95 1455 Q1236.03 1459.58 1236.03 1468.33 Q1236.03 1477.06 1232.95 1481.67 Q1229.9 1486.25 1224.09 1486.25 Q1218.28 1486.25 1215.2 1481.67 Q1212.14 1477.06 1212.14 1468.33 Q1212.14 1459.58 1215.2 1455 Q1218.28 1450.39 1224.09 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1293.46 1481.64 L1301.09 1481.64 L1301.09 1455.28 L1292.78 1456.95 L1292.78 1452.69 L1301.05 1451.02 L1305.72 1451.02 L1305.72 1481.64 L1313.36 1481.64 L1313.36 1485.58 L1293.46 1485.58 L1293.46 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1323.62 1481.64 L1331.26 1481.64 L1331.26 1455.28 L1322.95 1456.95 L1322.95 1452.69 L1331.21 1451.02 L1335.89 1451.02 L1335.89 1481.64 L1343.53 1481.64 L1343.53 1485.58 L1323.62 1485.58 L1323.62 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1401.75 1481.64 L1409.39 1481.64 L1409.39 1455.28 L1401.08 1456.95 L1401.08 1452.69 L1409.34 1451.02 L1414.02 1451.02 L1414.02 1481.64 L1421.66 1481.64 L1421.66 1485.58 L1401.75 1485.58 L1401.75 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1435.13 1481.64 L1451.45 1481.64 L1451.45 1485.58 L1429.5 1485.58 L1429.5 1481.64 Q1432.17 1478.89 1436.75 1474.26 Q1441.36 1469.61 1442.54 1468.27 Q1444.78 1465.74 1445.66 1464.01 Q1446.56 1462.25 1446.56 1460.56 Q1446.56 1457.8 1444.62 1456.07 Q1442.7 1454.33 1439.6 1454.33 Q1437.4 1454.33 1434.94 1455.09 Q1432.51 1455.86 1429.74 1457.41 L1429.74 1452.69 Q1432.56 1451.55 1435.01 1450.97 Q1437.47 1450.39 1439.5 1450.39 Q1444.87 1450.39 1448.07 1453.08 Q1451.26 1455.77 1451.26 1460.26 Q1451.26 1462.39 1450.45 1464.31 Q1449.67 1466.2 1447.56 1468.8 Q1446.98 1469.47 1443.88 1472.69 Q1440.78 1475.88 1435.13 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1509.38 1481.64 L1517.02 1481.64 L1517.02 1455.28 L1508.71 1456.95 L1508.71 1452.69 L1516.98 1451.02 L1521.65 1451.02 L1521.65 1481.64 L1529.29 1481.64 L1529.29 1485.58 L1509.38 1485.58 L1509.38 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1552.9 1466.95 Q1556.26 1467.66 1558.13 1469.93 Q1560.03 1472.2 1560.03 1475.53 Q1560.03 1480.65 1556.51 1483.45 Q1553 1486.25 1546.51 1486.25 Q1544.34 1486.25 1542.02 1485.81 Q1539.73 1485.39 1537.28 1484.54 L1537.28 1480.02 Q1539.22 1481.16 1541.54 1481.74 Q1543.85 1482.32 1546.37 1482.32 Q1550.77 1482.32 1553.06 1480.58 Q1555.38 1478.84 1555.38 1475.53 Q1555.38 1472.48 1553.23 1470.77 Q1551.1 1469.03 1547.28 1469.03 L1543.25 1469.03 L1543.25 1465.19 L1547.46 1465.19 Q1550.91 1465.19 1552.74 1463.82 Q1554.57 1462.43 1554.57 1459.84 Q1554.57 1457.18 1552.67 1455.77 Q1550.8 1454.33 1547.28 1454.33 Q1545.36 1454.33 1543.16 1454.75 Q1540.96 1455.16 1538.32 1456.04 L1538.32 1451.88 Q1540.98 1451.14 1543.3 1450.77 Q1545.63 1450.39 1547.69 1450.39 Q1553.02 1450.39 1556.12 1452.83 Q1559.22 1455.23 1559.22 1459.35 Q1559.22 1462.22 1557.58 1464.21 Q1555.93 1466.18 1552.9 1466.95 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1616.93 1481.64 L1624.56 1481.64 L1624.56 1455.28 L1616.25 1456.95 L1616.25 1452.69 L1624.52 1451.02 L1629.19 1451.02 L1629.19 1481.64 L1636.83 1481.64 L1636.83 1485.58 L1616.93 1485.58 L1616.93 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1659.12 1455.09 L1647.32 1473.54 L1659.12 1473.54 L1659.12 1455.09 M1657.9 1451.02 L1663.78 1451.02 L1663.78 1473.54 L1668.71 1473.54 L1668.71 1477.43 L1663.78 1477.43 L1663.78 1485.58 L1659.12 1485.58 L1659.12 1477.43 L1643.52 1477.43 L1643.52 1472.92 L1657.9 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1725.78 1481.64 L1733.41 1481.64 L1733.41 1455.28 L1725.1 1456.95 L1725.1 1452.69 L1733.37 1451.02 L1738.04 1451.02 L1738.04 1481.64 L1745.68 1481.64 L1745.68 1485.58 L1725.78 1485.58 L1725.78 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1755.17 1451.02 L1773.53 1451.02 L1773.53 1454.96 L1759.46 1454.96 L1759.46 1463.43 Q1760.47 1463.08 1761.49 1462.92 Q1762.51 1462.73 1763.53 1462.73 Q1769.32 1462.73 1772.7 1465.9 Q1776.08 1469.08 1776.08 1474.49 Q1776.08 1480.07 1772.6 1483.17 Q1769.13 1486.25 1762.81 1486.25 Q1760.64 1486.25 1758.37 1485.88 Q1756.12 1485.51 1753.72 1484.77 L1753.72 1480.07 Q1755.8 1481.2 1758.02 1481.76 Q1760.24 1482.32 1762.72 1482.32 Q1766.72 1482.32 1769.06 1480.21 Q1771.4 1478.1 1771.4 1474.49 Q1771.4 1470.88 1769.06 1468.77 Q1766.72 1466.67 1762.72 1466.67 Q1760.84 1466.67 1758.97 1467.08 Q1757.12 1467.5 1755.17 1468.38 L1755.17 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1833.31 1481.64 L1840.94 1481.64 L1840.94 1455.28 L1832.63 1456.95 L1832.63 1452.69 L1840.9 1451.02 L1845.57 1451.02 L1845.57 1481.64 L1853.21 1481.64 L1853.21 1485.58 L1833.31 1485.58 L1833.31 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1873.24 1466.44 Q1870.09 1466.44 1868.24 1468.59 Q1866.41 1470.74 1866.41 1474.49 Q1866.41 1478.22 1868.24 1480.39 Q1870.09 1482.55 1873.24 1482.55 Q1876.38 1482.55 1878.21 1480.39 Q1880.06 1478.22 1880.06 1474.49 Q1880.06 1470.74 1878.21 1468.59 Q1876.38 1466.44 1873.24 1466.44 M1882.52 1451.78 L1882.52 1456.04 Q1880.76 1455.21 1878.95 1454.77 Q1877.17 1454.33 1875.41 1454.33 Q1870.78 1454.33 1868.33 1457.45 Q1865.9 1460.58 1865.55 1466.9 Q1866.92 1464.89 1868.98 1463.82 Q1871.04 1462.73 1873.51 1462.73 Q1878.72 1462.73 1881.73 1465.9 Q1884.76 1469.05 1884.76 1474.49 Q1884.76 1479.82 1881.62 1483.03 Q1878.47 1486.25 1873.24 1486.25 Q1867.24 1486.25 1864.07 1481.67 Q1860.9 1477.06 1860.9 1468.33 Q1860.9 1460.14 1864.79 1455.28 Q1868.68 1450.39 1875.23 1450.39 Q1876.99 1450.39 1878.77 1450.74 Q1880.57 1451.09 1882.52 1451.78 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1941.95 1481.64 L1949.59 1481.64 L1949.59 1455.28 L1941.28 1456.95 L1941.28 1452.69 L1949.54 1451.02 L1954.22 1451.02 L1954.22 1481.64 L1961.85 1481.64 L1961.85 1485.58 L1941.95 1485.58 L1941.95 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1970.12 1451.02 L1992.34 1451.02 L1992.34 1453.01 L1979.79 1485.58 L1974.91 1485.58 L1986.71 1454.96 L1970.12 1454.96 L1970.12 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2049.65 1481.64 L2057.29 1481.64 L2057.29 1455.28 L2048.98 1456.95 L2048.98 1452.69 L2057.24 1451.02 L2061.92 1451.02 L2061.92 1481.64 L2069.56 1481.64 L2069.56 1485.58 L2049.65 1485.58 L2049.65 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2089 1469.17 Q2085.67 1469.17 2083.75 1470.95 Q2081.85 1472.73 2081.85 1475.86 Q2081.85 1478.98 2083.75 1480.77 Q2085.67 1482.55 2089 1482.55 Q2092.34 1482.55 2094.26 1480.77 Q2096.18 1478.96 2096.18 1475.86 Q2096.18 1472.73 2094.26 1470.95 Q2092.36 1469.17 2089 1469.17 M2084.33 1467.18 Q2081.32 1466.44 2079.63 1464.38 Q2077.96 1462.32 2077.96 1459.35 Q2077.96 1455.21 2080.9 1452.8 Q2083.86 1450.39 2089 1450.39 Q2094.16 1450.39 2097.1 1452.8 Q2100.04 1455.21 2100.04 1459.35 Q2100.04 1462.32 2098.35 1464.38 Q2096.69 1466.44 2093.7 1467.18 Q2097.08 1467.96 2098.96 1470.26 Q2100.85 1472.55 2100.85 1475.86 Q2100.85 1480.88 2097.78 1483.57 Q2094.72 1486.25 2089 1486.25 Q2083.28 1486.25 2080.21 1483.57 Q2077.15 1480.88 2077.15 1475.86 Q2077.15 1472.55 2079.05 1470.26 Q2080.95 1467.96 2084.33 1467.18 M2082.61 1459.79 Q2082.61 1462.48 2084.28 1463.98 Q2085.97 1465.49 2089 1465.49 Q2092.01 1465.49 2093.7 1463.98 Q2095.41 1462.48 2095.41 1459.79 Q2095.41 1457.11 2093.7 1455.6 Q2092.01 1454.1 2089 1454.1 Q2085.97 1454.1 2084.28 1455.6 Q2082.61 1457.11 2082.61 1459.79 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2157.81 1481.64 L2165.44 1481.64 L2165.44 1455.28 L2157.13 1456.95 L2157.13 1452.69 L2165.4 1451.02 L2170.07 1451.02 L2170.07 1481.64 L2177.71 1481.64 L2177.71 1485.58 L2157.81 1485.58 L2157.81 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2187.3 1484.86 L2187.3 1480.6 Q2189.06 1481.44 2190.86 1481.88 Q2192.67 1482.32 2194.4 1482.32 Q2199.03 1482.32 2201.46 1479.21 Q2203.92 1476.09 2204.26 1469.75 Q2202.92 1471.74 2200.86 1472.8 Q2198.8 1473.87 2196.3 1473.87 Q2191.12 1473.87 2188.08 1470.74 Q2185.07 1467.59 2185.07 1462.15 Q2185.07 1456.83 2188.22 1453.61 Q2191.37 1450.39 2196.6 1450.39 Q2202.6 1450.39 2205.74 1455 Q2208.92 1459.58 2208.92 1468.33 Q2208.92 1476.51 2205.03 1481.39 Q2201.16 1486.25 2194.61 1486.25 Q2192.85 1486.25 2191.05 1485.9 Q2189.24 1485.56 2187.3 1484.86 M2196.6 1470.21 Q2199.75 1470.21 2201.58 1468.06 Q2203.43 1465.9 2203.43 1462.15 Q2203.43 1458.43 2201.58 1456.27 Q2199.75 1454.1 2196.6 1454.1 Q2193.45 1454.1 2191.6 1456.27 Q2189.77 1458.43 2189.77 1462.15 Q2189.77 1465.9 2191.6 1468.06 Q2193.45 1470.21 2196.6 1470.21 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2269.91 1481.64 L2286.23 1481.64 L2286.23 1485.58 L2264.28 1485.58 L2264.28 1481.64 Q2266.94 1478.89 2271.53 1474.26 Q2276.13 1469.61 2277.31 1468.27 Q2279.56 1465.74 2280.44 1464.01 Q2281.34 1462.25 2281.34 1460.56 Q2281.34 1457.8 2279.4 1456.07 Q2277.48 1454.33 2274.37 1454.33 Q2272.18 1454.33 2269.72 1455.09 Q2267.29 1455.86 2264.51 1457.41 L2264.51 1452.69 Q2267.34 1451.55 2269.79 1450.97 Q2272.25 1450.39 2274.28 1450.39 Q2279.65 1450.39 2282.85 1453.08 Q2286.04 1455.77 2286.04 1460.26 Q2286.04 1462.39 2285.23 1464.31 Q2284.44 1466.2 2282.34 1468.8 Q2281.76 1469.47 2278.66 1472.69 Q2275.56 1475.88 2269.91 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2306.04 1454.1 Q2302.43 1454.1 2300.6 1457.66 Q2298.8 1461.2 2298.8 1468.33 Q2298.8 1475.44 2300.6 1479.01 Q2302.43 1482.55 2306.04 1482.55 Q2309.68 1482.55 2311.48 1479.01 Q2313.31 1475.44 2313.31 1468.33 Q2313.31 1461.2 2311.48 1457.66 Q2309.68 1454.1 2306.04 1454.1 M2306.04 1450.39 Q2311.85 1450.39 2314.91 1455 Q2317.99 1459.58 2317.99 1468.33 Q2317.99 1477.06 2314.91 1481.67 Q2311.85 1486.25 2306.04 1486.25 Q2300.23 1486.25 2297.15 1481.67 Q2294.1 1477.06 2294.1 1468.33 Q2294.1 1459.58 2297.15 1455 Q2300.23 1450.39 2306.04 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M987.383 1520.52 L993.813 1520.52 L993.813 1568.04 L987.383 1568.04 L987.383 1520.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1035.99 1546.53 L1035.99 1568.04 L1030.13 1568.04 L1030.13 1546.72 Q1030.13 1541.66 1028.16 1539.14 Q1026.18 1536.63 1022.24 1536.63 Q1017.49 1536.63 1014.76 1539.65 Q1012.02 1542.68 1012.02 1547.9 L1012.02 1568.04 L1006.13 1568.04 L1006.13 1532.4 L1012.02 1532.4 L1012.02 1537.93 Q1014.12 1534.72 1016.95 1533.13 Q1019.82 1531.54 1023.54 1531.54 Q1029.68 1531.54 1032.83 1535.36 Q1035.99 1539.14 1035.99 1546.53 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1070.39 1533.45 L1070.39 1538.98 Q1067.91 1537.71 1065.24 1537.07 Q1062.56 1536.44 1059.7 1536.44 Q1055.34 1536.44 1053.14 1537.77 Q1050.98 1539.11 1050.98 1541.79 Q1050.98 1543.82 1052.54 1545 Q1054.1 1546.15 1058.81 1547.2 L1060.81 1547.64 Q1067.05 1548.98 1069.66 1551.43 Q1072.3 1553.85 1072.3 1558.21 Q1072.3 1563.17 1068.36 1566.07 Q1064.44 1568.97 1057.57 1568.97 Q1054.7 1568.97 1051.58 1568.39 Q1048.49 1567.85 1045.06 1566.74 L1045.06 1560.69 Q1048.3 1562.38 1051.45 1563.24 Q1054.61 1564.07 1057.69 1564.07 Q1061.83 1564.07 1064.06 1562.66 Q1066.29 1561.23 1066.29 1558.65 Q1066.29 1556.27 1064.66 1554.99 Q1063.07 1553.72 1057.63 1552.54 L1055.59 1552.07 Q1050.15 1550.92 1047.73 1548.56 Q1045.31 1546.18 1045.31 1542.04 Q1045.31 1537.01 1048.88 1534.27 Q1052.44 1531.54 1059 1531.54 Q1062.24 1531.54 1065.11 1532.01 Q1067.97 1532.49 1070.39 1533.45 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1087.42 1522.27 L1087.42 1532.4 L1099.48 1532.4 L1099.48 1536.95 L1087.42 1536.95 L1087.42 1556.3 Q1087.42 1560.66 1088.6 1561.9 Q1089.81 1563.14 1093.47 1563.14 L1099.48 1563.14 L1099.48 1568.04 L1093.47 1568.04 Q1086.69 1568.04 1084.11 1565.53 Q1081.53 1562.98 1081.53 1556.3 L1081.53 1536.95 L1077.24 1536.95 L1077.24 1532.4 L1081.53 1532.4 L1081.53 1522.27 L1087.42 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1123.39 1550.12 Q1116.29 1550.12 1113.55 1551.75 Q1110.81 1553.37 1110.81 1557.29 Q1110.81 1560.4 1112.85 1562.25 Q1114.92 1564.07 1118.45 1564.07 Q1123.32 1564.07 1126.25 1560.63 Q1129.21 1557.16 1129.21 1551.43 L1129.21 1550.12 L1123.39 1550.12 M1135.07 1547.71 L1135.07 1568.04 L1129.21 1568.04 L1129.21 1562.63 Q1127.21 1565.88 1124.21 1567.44 Q1121.22 1568.97 1116.89 1568.97 Q1111.42 1568.97 1108.17 1565.91 Q1104.96 1562.82 1104.96 1557.67 Q1104.96 1551.65 1108.97 1548.6 Q1113.01 1545.54 1121 1545.54 L1129.21 1545.54 L1129.21 1544.97 Q1129.21 1540.93 1126.54 1538.73 Q1123.9 1536.5 1119.09 1536.5 Q1116.03 1536.5 1113.14 1537.23 Q1110.24 1537.97 1107.57 1539.43 L1107.57 1534.02 Q1110.78 1532.78 1113.81 1532.17 Q1116.83 1531.54 1119.69 1531.54 Q1127.43 1531.54 1131.25 1535.55 Q1135.07 1539.56 1135.07 1547.71 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1176.76 1546.53 L1176.76 1568.04 L1170.91 1568.04 L1170.91 1546.72 Q1170.91 1541.66 1168.93 1539.14 Q1166.96 1536.63 1163.01 1536.63 Q1158.27 1536.63 1155.53 1539.65 Q1152.8 1542.68 1152.8 1547.9 L1152.8 1568.04 L1146.91 1568.04 L1146.91 1532.4 L1152.8 1532.4 L1152.8 1537.93 Q1154.9 1534.72 1157.73 1533.13 Q1160.59 1531.54 1164.32 1531.54 Q1170.46 1531.54 1173.61 1535.36 Q1176.76 1539.14 1176.76 1546.53 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1214.1 1533.76 L1214.1 1539.24 Q1211.62 1537.87 1209.1 1537.2 Q1206.62 1536.5 1204.07 1536.5 Q1198.37 1536.5 1195.22 1540.13 Q1192.07 1543.73 1192.07 1550.25 Q1192.07 1556.78 1195.22 1560.4 Q1198.37 1564 1204.07 1564 Q1206.62 1564 1209.1 1563.33 Q1211.62 1562.63 1214.1 1561.26 L1214.1 1566.68 Q1211.65 1567.82 1209.01 1568.39 Q1206.4 1568.97 1203.44 1568.97 Q1195.38 1568.97 1190.64 1563.91 Q1185.9 1558.85 1185.9 1550.25 Q1185.9 1541.53 1190.67 1536.53 Q1195.48 1531.54 1203.82 1531.54 Q1206.52 1531.54 1209.1 1532.11 Q1211.68 1532.65 1214.1 1533.76 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1254.77 1548.76 L1254.77 1551.62 L1227.85 1551.62 Q1228.23 1557.67 1231.48 1560.85 Q1234.75 1564 1240.58 1564 Q1243.95 1564 1247.1 1563.17 Q1250.29 1562.35 1253.41 1560.69 L1253.41 1566.23 Q1250.26 1567.57 1246.94 1568.27 Q1243.63 1568.97 1240.23 1568.97 Q1231.7 1568.97 1226.7 1564 Q1221.74 1559.04 1221.74 1550.57 Q1221.74 1541.82 1226.45 1536.69 Q1231.19 1531.54 1239.21 1531.54 Q1246.4 1531.54 1250.57 1536.18 Q1254.77 1540.8 1254.77 1548.76 M1248.92 1547.04 Q1248.85 1542.23 1246.21 1539.37 Q1243.6 1536.5 1239.27 1536.5 Q1234.37 1536.5 1231.41 1539.27 Q1228.48 1542.04 1228.04 1547.07 L1248.92 1547.04 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1285.36 1520.52 L1294.02 1520.52 L1315.09 1560.28 L1315.09 1520.52 L1321.33 1520.52 L1321.33 1568.04 L1312.67 1568.04 L1291.6 1528.29 L1291.6 1568.04 L1285.36 1568.04 L1285.36 1520.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1333.26 1553.98 L1333.26 1532.4 L1339.12 1532.4 L1339.12 1553.75 Q1339.12 1558.81 1341.09 1561.36 Q1343.07 1563.87 1347.01 1563.87 Q1351.76 1563.87 1354.49 1560.85 Q1357.26 1557.83 1357.26 1552.61 L1357.26 1532.4 L1363.12 1532.4 L1363.12 1568.04 L1357.26 1568.04 L1357.26 1562.57 Q1355.13 1565.82 1352.3 1567.41 Q1349.5 1568.97 1345.77 1568.97 Q1339.63 1568.97 1336.45 1565.15 Q1333.26 1561.33 1333.26 1553.98 M1348 1531.54 L1348 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1402.94 1539.24 Q1405.13 1535.29 1408.19 1533.41 Q1411.24 1531.54 1415.38 1531.54 Q1420.95 1531.54 1423.98 1535.45 Q1427 1539.33 1427 1546.53 L1427 1568.04 L1421.11 1568.04 L1421.11 1546.72 Q1421.11 1541.59 1419.3 1539.11 Q1417.48 1536.63 1413.76 1536.63 Q1409.21 1536.63 1406.57 1539.65 Q1403.92 1542.68 1403.92 1547.9 L1403.92 1568.04 L1398.04 1568.04 L1398.04 1546.72 Q1398.04 1541.56 1396.22 1539.11 Q1394.41 1536.63 1390.62 1536.63 Q1386.13 1536.63 1383.49 1539.68 Q1380.85 1542.71 1380.85 1547.9 L1380.85 1568.04 L1374.96 1568.04 L1374.96 1532.4 L1380.85 1532.4 L1380.85 1537.93 Q1382.85 1534.66 1385.65 1533.1 Q1388.45 1531.54 1392.31 1531.54 Q1396.19 1531.54 1398.89 1533.51 Q1401.63 1535.48 1402.94 1539.24 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1464.27 1550.25 Q1464.27 1543.79 1461.6 1540.13 Q1458.95 1536.44 1454.31 1536.44 Q1449.66 1536.44 1446.99 1540.13 Q1444.35 1543.79 1444.35 1550.25 Q1444.35 1556.71 1446.99 1560.4 Q1449.66 1564.07 1454.31 1564.07 Q1458.95 1564.07 1461.6 1560.4 Q1464.27 1556.71 1464.27 1550.25 M1444.35 1537.81 Q1446.19 1534.62 1448.99 1533.1 Q1451.83 1531.54 1455.74 1531.54 Q1462.23 1531.54 1466.28 1536.69 Q1470.35 1541.85 1470.35 1550.25 Q1470.35 1558.65 1466.28 1563.81 Q1462.23 1568.97 1455.74 1568.97 Q1451.83 1568.97 1448.99 1567.44 Q1446.19 1565.88 1444.35 1562.7 L1444.35 1568.04 L1438.46 1568.04 L1438.46 1518.52 L1444.35 1518.52 L1444.35 1537.81 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1510.55 1548.76 L1510.55 1551.62 L1483.62 1551.62 Q1484 1557.67 1487.25 1560.85 Q1490.53 1564 1496.35 1564 Q1499.73 1564 1502.88 1563.17 Q1506.06 1562.35 1509.18 1560.69 L1509.18 1566.23 Q1506.03 1567.57 1502.72 1568.27 Q1499.41 1568.97 1496 1568.97 Q1487.47 1568.97 1482.48 1564 Q1477.51 1559.04 1477.51 1550.57 Q1477.51 1541.82 1482.22 1536.69 Q1486.96 1531.54 1494.98 1531.54 Q1502.18 1531.54 1506.35 1536.18 Q1510.55 1540.8 1510.55 1548.76 M1504.69 1547.04 Q1504.63 1542.23 1501.99 1539.37 Q1499.38 1536.5 1495.05 1536.5 Q1490.15 1536.5 1487.19 1539.27 Q1484.26 1542.04 1483.81 1547.07 L1504.69 1547.04 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1540.82 1537.87 Q1539.83 1537.3 1538.65 1537.04 Q1537.51 1536.76 1536.11 1536.76 Q1531.14 1536.76 1528.47 1540 Q1525.83 1543.22 1525.83 1549.27 L1525.83 1568.04 L1519.94 1568.04 L1519.94 1532.4 L1525.83 1532.4 L1525.83 1537.93 Q1527.67 1534.69 1530.63 1533.13 Q1533.59 1531.54 1537.83 1531.54 Q1538.43 1531.54 1539.16 1531.63 Q1539.89 1531.7 1540.79 1531.85 L1540.82 1537.87 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"175.445,1384.24 2352.76,1384.24 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"175.445,951.554 2352.76,951.554 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"175.445,518.87 2352.76,518.87 \"/>\n",
       "<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"175.445,86.1857 2352.76,86.1857 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"175.445,1423.18 175.445,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"175.445,1384.24 194.343,1384.24 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"175.445,951.554 194.343,951.554 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"175.445,518.87 194.343,518.87 \"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"175.445,86.1857 194.343,86.1857 \"/>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M119.538 1397.58 L127.177 1397.58 L127.177 1371.22 L118.867 1372.88 L118.867 1368.62 L127.13 1366.96 L131.806 1366.96 L131.806 1397.58 L139.445 1397.58 L139.445 1401.52 L119.538 1401.52 L119.538 1397.58 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M123.126 964.899 L139.445 964.899 L139.445 968.834 L117.501 968.834 L117.501 964.899 Q120.163 962.144 124.746 957.515 Q129.353 952.862 130.533 951.519 Q132.779 948.996 133.658 947.26 Q134.561 945.501 134.561 943.811 Q134.561 941.056 132.617 939.32 Q130.695 937.584 127.593 937.584 Q125.394 937.584 122.941 938.348 Q120.51 939.112 117.732 940.663 L117.732 935.941 Q120.556 934.806 123.01 934.228 Q125.464 933.649 127.501 933.649 Q132.871 933.649 136.066 936.334 Q139.26 939.019 139.26 943.51 Q139.26 945.64 138.45 947.561 Q137.663 949.459 135.556 952.052 Q134.978 952.723 131.876 955.941 Q128.774 959.135 123.126 964.899 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M132.316 517.516 Q135.672 518.233 137.547 520.502 Q139.445 522.77 139.445 526.104 Q139.445 531.219 135.927 534.02 Q132.408 536.821 125.927 536.821 Q123.751 536.821 121.436 536.381 Q119.144 535.965 116.691 535.108 L116.691 530.594 Q118.635 531.729 120.95 532.307 Q123.265 532.886 125.788 532.886 Q130.186 532.886 132.478 531.15 Q134.792 529.414 134.792 526.104 Q134.792 523.048 132.64 521.335 Q130.51 519.599 126.691 519.599 L122.663 519.599 L122.663 515.756 L126.876 515.756 Q130.325 515.756 132.154 514.391 Q133.982 513.002 133.982 510.409 Q133.982 507.747 132.084 506.335 Q130.209 504.9 126.691 504.9 Q124.769 504.9 122.57 505.317 Q120.371 505.733 117.732 506.613 L117.732 502.446 Q120.394 501.706 122.709 501.335 Q125.047 500.965 127.107 500.965 Q132.431 500.965 135.533 503.395 Q138.635 505.803 138.635 509.923 Q138.635 512.794 136.992 514.784 Q135.348 516.752 132.316 517.516 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M129.862 72.9797 L118.056 91.4287 L129.862 91.4287 L129.862 72.9797 M128.635 68.9057 L134.515 68.9057 L134.515 91.4287 L139.445 91.4287 L139.445 95.3176 L134.515 95.3176 L134.515 103.466 L129.862 103.466 L129.862 95.3176 L114.26 95.3176 L114.26 90.8037 L128.635 68.9057 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M16.4842 940.968 L16.4842 913.659 L21.895 913.659 L21.895 934.538 L35.8996 934.538 L35.8996 915.696 L41.3104 915.696 L41.3104 934.538 L64.0042 934.538 L64.0042 940.968 L16.4842 940.968 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M28.3562 908.471 L28.3562 902.614 L64.0042 902.614 L64.0042 908.471 L28.3562 908.471 M14.479 908.471 L14.479 902.614 L21.895 902.614 L21.895 908.471 L14.479 908.471 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M33.8307 869.703 Q33.2578 870.69 33.0032 871.868 Q32.7167 873.014 32.7167 874.414 Q32.7167 879.379 35.9632 882.053 Q39.1779 884.695 45.2253 884.695 L64.0042 884.695 L64.0042 890.583 L28.3562 890.583 L28.3562 884.695 L33.8944 884.695 Q30.6479 882.849 29.0883 879.889 Q27.4968 876.929 27.4968 872.695 Q27.4968 872.091 27.5923 871.359 Q27.656 870.626 27.8151 869.735 L33.8307 869.703 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M29.4065 840.835 L34.9447 840.835 Q33.6716 843.318 33.035 845.991 Q32.3984 848.665 32.3984 851.529 Q32.3984 855.89 33.7352 858.086 Q35.072 860.25 37.7456 860.25 Q39.7826 860.25 40.9603 858.691 Q42.1061 857.131 43.1565 852.421 L43.6021 850.415 Q44.9389 844.177 47.3897 841.567 Q49.8086 838.925 54.1691 838.925 Q59.1344 838.925 62.0308 842.872 Q64.9272 846.787 64.9272 853.662 Q64.9272 856.526 64.3543 859.646 Q63.8132 862.733 62.6992 866.17 L56.6518 866.17 Q58.3387 862.924 59.198 859.773 Q60.0256 856.622 60.0256 853.535 Q60.0256 849.397 58.6251 847.169 Q57.1929 844.941 54.6147 844.941 Q52.2276 844.941 50.9545 846.564 Q49.6813 848.156 48.5037 853.598 L48.0262 855.635 Q46.8804 861.078 44.5251 863.497 Q42.138 865.916 38.0002 865.916 Q32.9713 865.916 30.2341 862.351 Q27.4968 858.786 27.4968 852.23 Q27.4968 848.983 27.9743 846.118 Q28.4517 843.254 29.4065 840.835 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M18.2347 823.807 L28.3562 823.807 L28.3562 811.744 L32.9077 811.744 L32.9077 823.807 L52.2594 823.807 Q56.6199 823.807 57.8613 822.629 Q59.1026 821.42 59.1026 817.759 L59.1026 811.744 L64.0042 811.744 L64.0042 817.759 Q64.0042 824.539 61.4897 827.117 Q58.9434 829.695 52.2594 829.695 L32.9077 829.695 L32.9077 833.992 L28.3562 833.992 L28.3562 829.695 L18.2347 829.695 L18.2347 823.807 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M18.0438 754.58 L24.314 754.58 Q22.5634 758.24 21.704 761.486 Q20.8447 764.733 20.8447 767.757 Q20.8447 773.008 22.8817 775.873 Q24.9187 778.706 28.6745 778.706 Q31.8255 778.706 33.4488 776.828 Q35.0402 774.918 36.0269 769.635 L36.8226 765.751 Q38.1912 758.558 41.6605 755.153 Q45.098 751.715 50.8908 751.715 Q57.7976 751.715 61.3624 756.362 Q64.9272 760.977 64.9272 769.921 Q64.9272 773.295 64.1633 777.114 Q63.3994 780.902 61.9035 784.976 L55.2831 784.976 Q57.4793 781.061 58.5933 777.305 Q59.7073 773.549 59.7073 769.921 Q59.7073 764.415 57.543 761.423 Q55.3786 758.431 51.3682 758.431 Q47.8671 758.431 45.8937 760.595 Q43.9204 762.728 42.9337 767.629 L42.1698 771.544 Q40.7375 778.737 37.682 781.952 Q34.6264 785.167 29.1837 785.167 Q22.8817 785.167 19.2532 780.743 Q15.6248 776.287 15.6248 768.489 Q15.6248 765.147 16.2295 761.677 Q16.8343 758.208 18.0438 754.58 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M32.4621 728.13 Q32.4621 732.841 36.1542 735.578 Q39.8145 738.315 46.212 738.315 Q52.6095 738.315 56.3017 735.61 Q59.9619 732.873 59.9619 728.13 Q59.9619 723.451 56.2698 720.714 Q52.5777 717.977 46.212 717.977 Q39.8781 717.977 36.186 720.714 Q32.4621 723.451 32.4621 728.13 M27.4968 728.13 Q27.4968 720.491 32.4621 716.131 Q37.4273 711.77 46.212 711.77 Q54.9649 711.77 59.9619 716.131 Q64.9272 720.491 64.9272 728.13 Q64.9272 735.801 59.9619 740.161 Q54.9649 744.49 46.212 744.49 Q37.4273 744.49 32.4621 740.161 Q27.4968 735.801 27.4968 728.13 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M14.479 702.063 L14.479 696.206 L64.0042 696.206 L64.0042 702.063 L14.479 702.063 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M49.9359 684.557 L28.3562 684.557 L28.3562 678.7 L49.7131 678.7 Q54.7739 678.7 57.3202 676.727 Q59.8346 674.754 59.8346 670.807 Q59.8346 666.064 56.8109 663.327 Q53.7872 660.558 48.5673 660.558 L28.3562 660.558 L28.3562 654.702 L64.0042 654.702 L64.0042 660.558 L58.5296 660.558 Q61.7762 662.691 63.3676 665.523 Q64.9272 668.324 64.9272 672.048 Q64.9272 678.191 61.1078 681.374 Q57.2883 684.557 49.9359 684.557 M27.4968 669.82 L27.4968 669.82 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M18.2347 636.846 L28.3562 636.846 L28.3562 624.783 L32.9077 624.783 L32.9077 636.846 L52.2594 636.846 Q56.6199 636.846 57.8613 635.668 Q59.1026 634.459 59.1026 630.798 L59.1026 624.783 L64.0042 624.783 L64.0042 630.798 Q64.0042 637.578 61.4897 640.156 Q58.9434 642.734 52.2594 642.734 L32.9077 642.734 L32.9077 647.031 L28.3562 647.031 L28.3562 642.734 L18.2347 642.734 L18.2347 636.846 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M28.3562 617.08 L28.3562 611.224 L64.0042 611.224 L64.0042 617.08 L28.3562 617.08 M14.479 617.08 L14.479 611.224 L21.895 611.224 L21.895 617.08 L14.479 617.08 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M32.4621 585.156 Q32.4621 589.867 36.1542 592.604 Q39.8145 595.341 46.212 595.341 Q52.6095 595.341 56.3017 592.636 Q59.9619 589.899 59.9619 585.156 Q59.9619 580.478 56.2698 577.74 Q52.5777 575.003 46.212 575.003 Q39.8781 575.003 36.186 577.74 Q32.4621 580.478 32.4621 585.156 M27.4968 585.156 Q27.4968 577.518 32.4621 573.157 Q37.4273 568.796 46.212 568.796 Q54.9649 568.796 59.9619 573.157 Q64.9272 577.518 64.9272 585.156 Q64.9272 592.827 59.9619 597.188 Q54.9649 601.516 46.212 601.516 Q37.4273 601.516 32.4621 597.188 Q27.4968 592.827 27.4968 585.156 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M42.4881 529.456 L64.0042 529.456 L64.0042 535.313 L42.679 535.313 Q37.6183 535.313 35.1038 537.286 Q32.5894 539.26 32.5894 543.206 Q32.5894 547.949 35.6131 550.686 Q38.6368 553.423 43.8567 553.423 L64.0042 553.423 L64.0042 559.312 L28.3562 559.312 L28.3562 553.423 L33.8944 553.423 Q30.6797 551.323 29.0883 548.49 Q27.4968 545.625 27.4968 541.901 Q27.4968 535.758 31.3163 532.607 Q35.1038 529.456 42.4881 529.456 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip392)\" cx=\"237.067\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"345.176\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"453.285\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"561.394\" cy=\"86.1857\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"669.502\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"777.611\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"885.72\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"993.829\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1101.94\" cy=\"86.1857\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1210.05\" cy=\"951.554\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1318.15\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1426.26\" cy=\"951.554\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1534.37\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1642.48\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1750.59\" cy=\"951.554\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1858.7\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1966.81\" cy=\"86.1857\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2074.92\" cy=\"86.1857\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2183.03\" cy=\"86.1857\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2291.13\" cy=\"518.87\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"237.067\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"345.176\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"453.285\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"561.394\" cy=\"86.1857\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"669.502\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"777.611\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"885.72\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"993.829\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1101.94\" cy=\"86.1857\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1210.05\" cy=\"951.554\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1318.15\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1426.26\" cy=\"951.554\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1534.37\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1642.48\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1750.59\" cy=\"951.554\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1858.7\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1966.81\" cy=\"86.1857\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2074.92\" cy=\"86.1857\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2183.03\" cy=\"86.1857\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2291.13\" cy=\"518.87\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"237.067\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"345.176\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"453.285\" cy=\"1384.24\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"561.394\" cy=\"518.87\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"669.502\" cy=\"518.87\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"777.611\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"885.72\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"993.829\" cy=\"518.87\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1101.94\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1210.05\" cy=\"1384.24\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1318.15\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1426.26\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1534.37\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1642.48\" cy=\"518.87\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1750.59\" cy=\"1384.24\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1858.7\" cy=\"951.554\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"1966.81\" cy=\"86.1857\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2074.92\" cy=\"1384.24\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2183.03\" cy=\"518.87\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip392)\" cx=\"2291.13\" cy=\"518.87\" r=\"14.4\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M1504.84 1377.32 L2280.18 1377.32 L2280.18 1169.96 L1504.84 1169.96  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1504.84,1377.32 2280.18,1377.32 2280.18,1169.96 1504.84,1169.96 1504.84,1377.32 \"/>\n",
       "<circle clip-path=\"url(#clip390)\" cx=\"1601.6\" cy=\"1221.8\" r=\"21.6847\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"2.40941\"/>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M1720.62 1205.65 L1720.62 1210.21 Q1717.96 1208.94 1715.6 1208.31 Q1713.23 1207.69 1711.04 1207.69 Q1707.22 1207.69 1705.13 1209.17 Q1703.07 1210.65 1703.07 1213.38 Q1703.07 1215.67 1704.44 1216.85 Q1705.83 1218.01 1709.67 1218.73 L1712.49 1219.31 Q1717.73 1220.3 1720.2 1222.83 Q1722.7 1225.33 1722.7 1229.54 Q1722.7 1234.56 1719.32 1237.15 Q1715.97 1239.75 1709.46 1239.75 Q1707.01 1239.75 1704.23 1239.19 Q1701.48 1238.64 1698.51 1237.55 L1698.51 1232.73 Q1701.36 1234.33 1704.09 1235.14 Q1706.82 1235.95 1709.46 1235.95 Q1713.47 1235.95 1715.64 1234.38 Q1717.82 1232.8 1717.82 1229.89 Q1717.82 1227.34 1716.24 1225.9 Q1714.69 1224.47 1711.13 1223.75 L1708.28 1223.2 Q1703.05 1222.15 1700.71 1219.93 Q1698.37 1217.71 1698.37 1213.75 Q1698.37 1209.17 1701.59 1206.53 Q1704.83 1203.89 1710.5 1203.89 Q1712.93 1203.89 1715.46 1204.33 Q1717.98 1204.77 1720.62 1205.65 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1729.81 1213.15 L1734.07 1213.15 L1734.07 1239.08 L1729.81 1239.08 L1729.81 1213.15 M1729.81 1203.06 L1734.07 1203.06 L1734.07 1208.45 L1729.81 1208.45 L1729.81 1203.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1763.17 1218.13 Q1764.76 1215.26 1766.98 1213.89 Q1769.21 1212.52 1772.22 1212.52 Q1776.27 1212.52 1778.47 1215.37 Q1780.67 1218.2 1780.67 1223.43 L1780.67 1239.08 L1776.38 1239.08 L1776.38 1223.57 Q1776.38 1219.84 1775.06 1218.03 Q1773.74 1216.23 1771.04 1216.23 Q1767.73 1216.23 1765.8 1218.43 Q1763.88 1220.63 1763.88 1224.42 L1763.88 1239.08 L1759.6 1239.08 L1759.6 1223.57 Q1759.6 1219.82 1758.28 1218.03 Q1756.96 1216.23 1754.21 1216.23 Q1750.94 1216.23 1749.02 1218.45 Q1747.1 1220.65 1747.1 1224.42 L1747.1 1239.08 L1742.82 1239.08 L1742.82 1213.15 L1747.1 1213.15 L1747.1 1217.18 Q1748.56 1214.79 1750.6 1213.66 Q1752.63 1212.52 1755.43 1212.52 Q1758.26 1212.52 1760.23 1213.96 Q1762.22 1215.39 1763.17 1218.13 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1793.28 1235.19 L1793.28 1248.94 L1789 1248.94 L1789 1213.15 L1793.28 1213.15 L1793.28 1217.08 Q1794.62 1214.77 1796.66 1213.66 Q1798.72 1212.52 1801.57 1212.52 Q1806.29 1212.52 1809.23 1216.27 Q1812.19 1220.02 1812.19 1226.14 Q1812.19 1232.25 1809.23 1236 Q1806.29 1239.75 1801.57 1239.75 Q1798.72 1239.75 1796.66 1238.64 Q1794.62 1237.5 1793.28 1235.19 M1807.77 1226.14 Q1807.77 1221.44 1805.83 1218.77 Q1803.91 1216.09 1800.53 1216.09 Q1797.15 1216.09 1795.2 1218.77 Q1793.28 1221.44 1793.28 1226.14 Q1793.28 1230.83 1795.2 1233.52 Q1797.15 1236.18 1800.53 1236.18 Q1803.91 1236.18 1805.83 1233.52 Q1807.77 1230.83 1807.77 1226.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1819.25 1203.06 L1823.51 1203.06 L1823.51 1239.08 L1819.25 1239.08 L1819.25 1203.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1854.6 1225.05 L1854.6 1227.13 L1835.02 1227.13 Q1835.29 1231.53 1837.66 1233.84 Q1840.04 1236.14 1844.28 1236.14 Q1846.73 1236.14 1849.02 1235.53 Q1851.34 1234.93 1853.6 1233.73 L1853.6 1237.76 Q1851.31 1238.73 1848.91 1239.24 Q1846.5 1239.75 1844.02 1239.75 Q1837.82 1239.75 1834.18 1236.14 Q1830.57 1232.52 1830.57 1226.37 Q1830.57 1220 1834 1216.27 Q1837.45 1212.52 1843.28 1212.52 Q1848.51 1212.52 1851.54 1215.9 Q1854.6 1219.26 1854.6 1225.05 M1850.34 1223.8 Q1850.29 1220.3 1848.37 1218.22 Q1846.47 1216.14 1843.33 1216.14 Q1839.76 1216.14 1837.61 1218.15 Q1835.48 1220.16 1835.16 1223.82 L1850.34 1223.8 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1861.78 1204.52 L1866.45 1204.52 L1866.45 1235.14 L1883.28 1235.14 L1883.28 1239.08 L1861.78 1239.08 L1861.78 1204.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1909.34 1225.05 L1909.34 1227.13 L1889.76 1227.13 Q1890.04 1231.53 1892.4 1233.84 Q1894.78 1236.14 1899.02 1236.14 Q1901.47 1236.14 1903.77 1235.53 Q1906.08 1234.93 1908.35 1233.73 L1908.35 1237.76 Q1906.06 1238.73 1903.65 1239.24 Q1901.24 1239.75 1898.77 1239.75 Q1892.56 1239.75 1888.93 1236.14 Q1885.32 1232.52 1885.32 1226.37 Q1885.32 1220 1888.74 1216.27 Q1892.19 1212.52 1898.03 1212.52 Q1903.26 1212.52 1906.29 1215.9 Q1909.34 1219.26 1909.34 1225.05 M1905.09 1223.8 Q1905.04 1220.3 1903.12 1218.22 Q1901.22 1216.14 1898.07 1216.14 Q1894.51 1216.14 1892.35 1218.15 Q1890.22 1220.16 1889.9 1223.82 L1905.09 1223.8 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1928.12 1226.04 Q1922.96 1226.04 1920.97 1227.22 Q1918.97 1228.4 1918.97 1231.25 Q1918.97 1233.52 1920.46 1234.86 Q1921.96 1236.18 1924.53 1236.18 Q1928.07 1236.18 1930.2 1233.68 Q1932.35 1231.16 1932.35 1226.99 L1932.35 1226.04 L1928.12 1226.04 M1936.61 1224.28 L1936.61 1239.08 L1932.35 1239.08 L1932.35 1235.14 Q1930.9 1237.5 1928.72 1238.64 Q1926.54 1239.75 1923.4 1239.75 Q1919.41 1239.75 1917.05 1237.52 Q1914.72 1235.28 1914.72 1231.53 Q1914.72 1227.15 1917.63 1224.93 Q1920.57 1222.71 1926.38 1222.71 L1932.35 1222.71 L1932.35 1222.29 Q1932.35 1219.35 1930.41 1217.76 Q1928.49 1216.14 1924.99 1216.14 Q1922.77 1216.14 1920.66 1216.67 Q1918.56 1217.2 1916.61 1218.27 L1916.61 1214.33 Q1918.95 1213.43 1921.15 1212.99 Q1923.35 1212.52 1925.43 1212.52 Q1931.06 1212.52 1933.84 1215.44 Q1936.61 1218.36 1936.61 1224.28 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1960.41 1217.13 Q1959.69 1216.71 1958.84 1216.53 Q1958 1216.32 1956.98 1216.32 Q1953.37 1216.32 1951.43 1218.68 Q1949.51 1221.02 1949.51 1225.42 L1949.51 1239.08 L1945.22 1239.08 L1945.22 1213.15 L1949.51 1213.15 L1949.51 1217.18 Q1950.85 1214.82 1953 1213.68 Q1955.15 1212.52 1958.23 1212.52 Q1958.67 1212.52 1959.21 1212.59 Q1959.74 1212.64 1960.39 1212.76 L1960.41 1217.13 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1985.59 1223.43 L1985.59 1239.08 L1981.34 1239.08 L1981.34 1223.57 Q1981.34 1219.89 1979.9 1218.06 Q1978.46 1216.23 1975.59 1216.23 Q1972.15 1216.23 1970.15 1218.43 Q1968.16 1220.63 1968.16 1224.42 L1968.16 1239.08 L1963.88 1239.08 L1963.88 1213.15 L1968.16 1213.15 L1968.16 1217.18 Q1969.69 1214.84 1971.75 1213.68 Q1973.84 1212.52 1976.54 1212.52 Q1981.01 1212.52 1983.3 1215.3 Q1985.59 1218.06 1985.59 1223.43 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2016.27 1225.05 L2016.27 1227.13 L1996.68 1227.13 Q1996.96 1231.53 1999.32 1233.84 Q2001.71 1236.14 2005.94 1236.14 Q2008.4 1236.14 2010.69 1235.53 Q2013 1234.93 2015.27 1233.73 L2015.27 1237.76 Q2012.98 1238.73 2010.57 1239.24 Q2008.16 1239.75 2005.69 1239.75 Q1999.48 1239.75 1995.85 1236.14 Q1992.24 1232.52 1992.24 1226.37 Q1992.24 1220 1995.66 1216.27 Q1999.11 1212.52 2004.95 1212.52 Q2010.18 1212.52 2013.21 1215.9 Q2016.27 1219.26 2016.27 1225.05 M2012.01 1223.8 Q2011.96 1220.3 2010.04 1218.22 Q2008.14 1216.14 2004.99 1216.14 Q2001.43 1216.14 1999.27 1218.15 Q1997.15 1220.16 1996.82 1223.82 L2012.01 1223.8 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2040.32 1217.08 L2040.32 1203.06 L2044.58 1203.06 L2044.58 1239.08 L2040.32 1239.08 L2040.32 1235.19 Q2038.97 1237.5 2036.91 1238.64 Q2034.88 1239.75 2032.01 1239.75 Q2027.31 1239.75 2024.34 1236 Q2021.4 1232.25 2021.4 1226.14 Q2021.4 1220.02 2024.34 1216.27 Q2027.31 1212.52 2032.01 1212.52 Q2034.88 1212.52 2036.91 1213.66 Q2038.97 1214.77 2040.32 1217.08 M2025.8 1226.14 Q2025.8 1230.83 2027.72 1233.52 Q2029.67 1236.18 2033.05 1236.18 Q2036.43 1236.18 2038.37 1233.52 Q2040.32 1230.83 2040.32 1226.14 Q2040.32 1221.44 2038.37 1218.77 Q2036.43 1216.09 2033.05 1216.09 Q2029.67 1216.09 2027.72 1218.77 Q2025.8 1221.44 2025.8 1226.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2053.53 1204.52 L2058.21 1204.52 L2058.21 1218.68 L2075.2 1218.68 L2075.2 1204.52 L2079.88 1204.52 L2079.88 1239.08 L2075.2 1239.08 L2075.2 1222.62 L2058.21 1222.62 L2058.21 1239.08 L2053.53 1239.08 L2053.53 1204.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2111.17 1225.05 L2111.17 1227.13 L2091.59 1227.13 Q2091.87 1231.53 2094.23 1233.84 Q2096.61 1236.14 2100.85 1236.14 Q2103.3 1236.14 2105.59 1235.53 Q2107.91 1234.93 2110.18 1233.73 L2110.18 1237.76 Q2107.89 1238.73 2105.48 1239.24 Q2103.07 1239.75 2100.59 1239.75 Q2094.39 1239.75 2090.76 1236.14 Q2087.14 1232.52 2087.14 1226.37 Q2087.14 1220 2090.57 1216.27 Q2094.02 1212.52 2099.85 1212.52 Q2105.08 1212.52 2108.12 1215.9 Q2111.17 1219.26 2111.17 1225.05 M2106.91 1223.8 Q2106.87 1220.3 2104.95 1218.22 Q2103.05 1216.14 2099.9 1216.14 Q2096.33 1216.14 2094.18 1218.15 Q2092.05 1220.16 2091.73 1223.82 L2106.91 1223.8 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2117.72 1228.84 L2117.72 1213.15 L2121.98 1213.15 L2121.98 1228.68 Q2121.98 1232.36 2123.42 1234.21 Q2124.85 1236.04 2127.72 1236.04 Q2131.17 1236.04 2133.16 1233.84 Q2135.18 1231.64 2135.18 1227.85 L2135.18 1213.15 L2139.44 1213.15 L2139.44 1239.08 L2135.18 1239.08 L2135.18 1235.09 Q2133.63 1237.45 2131.57 1238.61 Q2129.53 1239.75 2126.82 1239.75 Q2122.35 1239.75 2120.04 1236.97 Q2117.72 1234.19 2117.72 1228.84 M2128.44 1212.52 L2128.44 1212.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2163.23 1217.13 Q2162.51 1216.71 2161.66 1216.53 Q2160.83 1216.32 2159.81 1216.32 Q2156.2 1216.32 2154.25 1218.68 Q2152.33 1221.02 2152.33 1225.42 L2152.33 1239.08 L2148.05 1239.08 L2148.05 1213.15 L2152.33 1213.15 L2152.33 1217.18 Q2153.67 1214.82 2155.83 1213.68 Q2157.98 1212.52 2161.06 1212.52 Q2161.5 1212.52 2162.03 1212.59 Q2162.56 1212.64 2163.21 1212.76 L2163.23 1217.13 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2167.7 1213.15 L2171.96 1213.15 L2171.96 1239.08 L2167.7 1239.08 L2167.7 1213.15 M2167.7 1203.06 L2171.96 1203.06 L2171.96 1208.45 L2167.7 1208.45 L2167.7 1203.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2197.4 1213.91 L2197.4 1217.94 Q2195.59 1217.02 2193.65 1216.55 Q2191.7 1216.09 2189.62 1216.09 Q2186.45 1216.09 2184.85 1217.06 Q2183.28 1218.03 2183.28 1219.98 Q2183.28 1221.46 2184.41 1222.32 Q2185.55 1223.15 2188.97 1223.91 L2190.43 1224.24 Q2194.97 1225.21 2196.87 1226.99 Q2198.79 1228.75 2198.79 1231.92 Q2198.79 1235.53 2195.92 1237.64 Q2193.07 1239.75 2188.07 1239.75 Q2185.99 1239.75 2183.72 1239.33 Q2181.47 1238.94 2178.97 1238.13 L2178.97 1233.73 Q2181.33 1234.95 2183.63 1235.58 Q2185.92 1236.18 2188.16 1236.18 Q2191.17 1236.18 2192.79 1235.16 Q2194.41 1234.12 2194.41 1232.25 Q2194.41 1230.51 2193.23 1229.58 Q2192.07 1228.66 2188.12 1227.8 L2186.64 1227.46 Q2182.68 1226.62 2180.92 1224.91 Q2179.16 1223.17 2179.16 1220.16 Q2179.16 1216.51 2181.75 1214.52 Q2184.34 1212.52 2189.11 1212.52 Q2191.47 1212.52 2193.56 1212.87 Q2195.64 1213.22 2197.4 1213.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2209.78 1205.79 L2209.78 1213.15 L2218.56 1213.15 L2218.56 1216.46 L2209.78 1216.46 L2209.78 1230.53 Q2209.78 1233.7 2210.64 1234.61 Q2211.52 1235.51 2214.18 1235.51 L2218.56 1235.51 L2218.56 1239.08 L2214.18 1239.08 Q2209.25 1239.08 2207.38 1237.25 Q2205.5 1235.39 2205.5 1230.53 L2205.5 1216.46 L2202.38 1216.46 L2202.38 1213.15 L2205.5 1213.15 L2205.5 1205.79 L2209.78 1205.79 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2224.16 1213.15 L2228.42 1213.15 L2228.42 1239.08 L2224.16 1239.08 L2224.16 1213.15 M2224.16 1203.06 L2228.42 1203.06 L2228.42 1208.45 L2224.16 1208.45 L2224.16 1203.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2255.99 1214.14 L2255.99 1218.13 Q2254.18 1217.13 2252.35 1216.64 Q2250.55 1216.14 2248.69 1216.14 Q2244.55 1216.14 2242.26 1218.77 Q2239.97 1221.39 2239.97 1226.14 Q2239.97 1230.88 2242.26 1233.52 Q2244.55 1236.14 2248.69 1236.14 Q2250.55 1236.14 2252.35 1235.65 Q2254.18 1235.14 2255.99 1234.14 L2255.99 1238.08 Q2254.2 1238.91 2252.28 1239.33 Q2250.38 1239.75 2248.23 1239.75 Q2242.38 1239.75 2238.93 1236.07 Q2235.48 1232.39 2235.48 1226.14 Q2235.48 1219.79 2238.95 1216.16 Q2242.44 1212.52 2248.51 1212.52 Q2250.48 1212.52 2252.35 1212.94 Q2254.23 1213.33 2255.99 1214.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip390)\" cx=\"1601.6\" cy=\"1273.64\" r=\"20.48\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"4.55111\"/>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M1716.8 1265.75 L1716.8 1269.78 Q1714.99 1268.86 1713.05 1268.39 Q1711.11 1267.93 1709.02 1267.93 Q1705.85 1267.93 1704.25 1268.9 Q1702.68 1269.87 1702.68 1271.82 Q1702.68 1273.3 1703.81 1274.16 Q1704.95 1274.99 1708.37 1275.75 L1709.83 1276.08 Q1714.37 1277.05 1716.27 1278.83 Q1718.19 1280.59 1718.19 1283.76 Q1718.19 1287.37 1715.32 1289.48 Q1712.47 1291.59 1707.47 1291.59 Q1705.39 1291.59 1703.12 1291.17 Q1700.87 1290.78 1698.37 1289.97 L1698.37 1285.57 Q1700.73 1286.79 1703.03 1287.42 Q1705.32 1288.02 1707.56 1288.02 Q1710.57 1288.02 1712.19 1287 Q1713.81 1285.96 1713.81 1284.09 Q1713.81 1282.35 1712.63 1281.42 Q1711.48 1280.5 1707.52 1279.64 L1706.04 1279.3 Q1702.08 1278.46 1700.32 1276.75 Q1698.56 1275.01 1698.56 1272 Q1698.56 1268.35 1701.15 1266.36 Q1703.74 1264.36 1708.51 1264.36 Q1710.87 1264.36 1712.96 1264.71 Q1715.04 1265.06 1716.8 1265.75 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1747.15 1276.89 L1747.15 1278.97 L1727.56 1278.97 Q1727.84 1283.37 1730.2 1285.68 Q1732.59 1287.98 1736.82 1287.98 Q1739.28 1287.98 1741.57 1287.37 Q1743.88 1286.77 1746.15 1285.57 L1746.15 1289.6 Q1743.86 1290.57 1741.45 1291.08 Q1739.04 1291.59 1736.57 1291.59 Q1730.36 1291.59 1726.73 1287.98 Q1723.12 1284.36 1723.12 1278.21 Q1723.12 1271.84 1726.54 1268.11 Q1729.99 1264.36 1735.83 1264.36 Q1741.06 1264.36 1744.09 1267.74 Q1747.15 1271.1 1747.15 1276.89 M1742.89 1275.64 Q1742.84 1272.14 1740.92 1270.06 Q1739.02 1267.98 1735.87 1267.98 Q1732.31 1267.98 1730.16 1269.99 Q1728.03 1272 1727.7 1275.66 L1742.89 1275.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1754.14 1254.9 L1758.4 1254.9 L1758.4 1290.92 L1754.14 1290.92 L1754.14 1254.9 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1789.48 1276.89 L1789.48 1278.97 L1769.9 1278.97 Q1770.18 1283.37 1772.54 1285.68 Q1774.92 1287.98 1779.16 1287.98 Q1781.61 1287.98 1783.91 1287.37 Q1786.22 1286.77 1788.49 1285.57 L1788.49 1289.6 Q1786.2 1290.57 1783.79 1291.08 Q1781.38 1291.59 1778.91 1291.59 Q1772.7 1291.59 1769.07 1287.98 Q1765.46 1284.36 1765.46 1278.21 Q1765.46 1271.84 1768.88 1268.11 Q1772.33 1264.36 1778.17 1264.36 Q1783.4 1264.36 1786.43 1267.74 Q1789.48 1271.1 1789.48 1276.89 M1785.23 1275.64 Q1785.18 1272.14 1783.26 1270.06 Q1781.36 1267.98 1778.21 1267.98 Q1774.65 1267.98 1772.49 1269.99 Q1770.36 1272 1770.04 1275.66 L1785.23 1275.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1815.13 1265.98 L1815.13 1269.97 Q1813.33 1268.97 1811.5 1268.48 Q1809.69 1267.98 1807.84 1267.98 Q1803.7 1267.98 1801.41 1270.61 Q1799.11 1273.23 1799.11 1277.98 Q1799.11 1282.72 1801.41 1285.36 Q1803.7 1287.98 1807.84 1287.98 Q1809.69 1287.98 1811.5 1287.49 Q1813.33 1286.98 1815.13 1285.98 L1815.13 1289.92 Q1813.35 1290.75 1811.43 1291.17 Q1809.53 1291.59 1807.38 1291.59 Q1801.52 1291.59 1798.07 1287.91 Q1794.62 1284.23 1794.62 1277.98 Q1794.62 1271.63 1798.1 1268 Q1801.59 1264.36 1807.66 1264.36 Q1809.62 1264.36 1811.5 1264.78 Q1813.37 1265.17 1815.13 1265.98 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1826.75 1257.63 L1826.75 1264.99 L1835.53 1264.99 L1835.53 1268.3 L1826.75 1268.3 L1826.75 1282.37 Q1826.75 1285.54 1827.61 1286.45 Q1828.49 1287.35 1831.15 1287.35 L1835.53 1287.35 L1835.53 1290.92 L1831.15 1290.92 Q1826.22 1290.92 1824.35 1289.09 Q1822.47 1287.23 1822.47 1282.37 L1822.47 1268.3 L1819.35 1268.3 L1819.35 1264.99 L1822.47 1264.99 L1822.47 1257.63 L1826.75 1257.63 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1841.31 1256.36 L1848.28 1256.36 L1857.1 1279.87 L1865.97 1256.36 L1872.93 1256.36 L1872.93 1290.92 L1868.37 1290.92 L1868.37 1260.57 L1859.46 1284.27 L1854.76 1284.27 L1845.85 1260.57 L1845.85 1290.92 L1841.31 1290.92 L1841.31 1256.36 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1893.81 1277.88 Q1888.65 1277.88 1886.66 1279.06 Q1884.67 1280.24 1884.67 1283.09 Q1884.67 1285.36 1886.15 1286.7 Q1887.66 1288.02 1890.22 1288.02 Q1893.77 1288.02 1895.9 1285.52 Q1898.05 1283 1898.05 1278.83 L1898.05 1277.88 L1893.81 1277.88 M1902.31 1276.12 L1902.31 1290.92 L1898.05 1290.92 L1898.05 1286.98 Q1896.59 1289.34 1894.41 1290.48 Q1892.24 1291.59 1889.09 1291.59 Q1885.11 1291.59 1882.75 1289.36 Q1880.41 1287.12 1880.41 1283.37 Q1880.41 1278.99 1883.33 1276.77 Q1886.27 1274.55 1892.08 1274.55 L1898.05 1274.55 L1898.05 1274.13 Q1898.05 1271.19 1896.1 1269.6 Q1894.18 1267.98 1890.69 1267.98 Q1888.47 1267.98 1886.36 1268.51 Q1884.25 1269.04 1882.31 1270.11 L1882.31 1266.17 Q1884.65 1265.27 1886.85 1264.83 Q1889.04 1264.36 1891.13 1264.36 Q1896.75 1264.36 1899.53 1267.28 Q1902.31 1270.2 1902.31 1276.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1932.63 1264.99 L1923.26 1277.61 L1933.12 1290.92 L1928.09 1290.92 L1920.55 1280.73 L1913 1290.92 L1907.98 1290.92 L1918.05 1277.35 L1908.84 1264.99 L1913.86 1264.99 L1920.73 1274.23 L1927.61 1264.99 L1932.63 1264.99 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip390)\" cx=\"1601.6\" cy=\"1325.48\" r=\"20.48\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"4.55111\"/>\n",
       "<path clip-path=\"url(#clip390)\" d=\"M1716.8 1317.59 L1716.8 1321.62 Q1714.99 1320.7 1713.05 1320.23 Q1711.11 1319.77 1709.02 1319.77 Q1705.85 1319.77 1704.25 1320.74 Q1702.68 1321.71 1702.68 1323.66 Q1702.68 1325.14 1703.81 1326 Q1704.95 1326.83 1708.37 1327.59 L1709.83 1327.92 Q1714.37 1328.89 1716.27 1330.67 Q1718.19 1332.43 1718.19 1335.6 Q1718.19 1339.21 1715.32 1341.32 Q1712.47 1343.43 1707.47 1343.43 Q1705.39 1343.43 1703.12 1343.01 Q1700.87 1342.62 1698.37 1341.81 L1698.37 1337.41 Q1700.73 1338.63 1703.03 1339.26 Q1705.32 1339.86 1707.56 1339.86 Q1710.57 1339.86 1712.19 1338.84 Q1713.81 1337.8 1713.81 1335.93 Q1713.81 1334.19 1712.63 1333.26 Q1711.48 1332.34 1707.52 1331.48 L1706.04 1331.14 Q1702.08 1330.3 1700.32 1328.59 Q1698.56 1326.85 1698.56 1323.84 Q1698.56 1320.19 1701.15 1318.2 Q1703.74 1316.2 1708.51 1316.2 Q1710.87 1316.2 1712.96 1316.55 Q1715.04 1316.9 1716.8 1317.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1747.15 1328.73 L1747.15 1330.81 L1727.56 1330.81 Q1727.84 1335.21 1730.2 1337.52 Q1732.59 1339.82 1736.82 1339.82 Q1739.28 1339.82 1741.57 1339.21 Q1743.88 1338.61 1746.15 1337.41 L1746.15 1341.44 Q1743.86 1342.41 1741.45 1342.92 Q1739.04 1343.43 1736.57 1343.43 Q1730.36 1343.43 1726.73 1339.82 Q1723.12 1336.2 1723.12 1330.05 Q1723.12 1323.68 1726.54 1319.95 Q1729.99 1316.2 1735.83 1316.2 Q1741.06 1316.2 1744.09 1319.58 Q1747.15 1322.94 1747.15 1328.73 M1742.89 1327.48 Q1742.84 1323.98 1740.92 1321.9 Q1739.02 1319.82 1735.87 1319.82 Q1732.31 1319.82 1730.16 1321.83 Q1728.03 1323.84 1727.7 1327.5 L1742.89 1327.48 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1754.14 1306.74 L1758.4 1306.74 L1758.4 1342.76 L1754.14 1342.76 L1754.14 1306.74 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1789.48 1328.73 L1789.48 1330.81 L1769.9 1330.81 Q1770.18 1335.21 1772.54 1337.52 Q1774.92 1339.82 1779.16 1339.82 Q1781.61 1339.82 1783.91 1339.21 Q1786.22 1338.61 1788.49 1337.41 L1788.49 1341.44 Q1786.2 1342.41 1783.79 1342.92 Q1781.38 1343.43 1778.91 1343.43 Q1772.7 1343.43 1769.07 1339.82 Q1765.46 1336.2 1765.46 1330.05 Q1765.46 1323.68 1768.88 1319.95 Q1772.33 1316.2 1778.17 1316.2 Q1783.4 1316.2 1786.43 1319.58 Q1789.48 1322.94 1789.48 1328.73 M1785.23 1327.48 Q1785.18 1323.98 1783.26 1321.9 Q1781.36 1319.82 1778.21 1319.82 Q1774.65 1319.82 1772.49 1321.83 Q1770.36 1323.84 1770.04 1327.5 L1785.23 1327.48 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1815.13 1317.82 L1815.13 1321.81 Q1813.33 1320.81 1811.5 1320.32 Q1809.69 1319.82 1807.84 1319.82 Q1803.7 1319.82 1801.41 1322.45 Q1799.11 1325.07 1799.11 1329.82 Q1799.11 1334.56 1801.41 1337.2 Q1803.7 1339.82 1807.84 1339.82 Q1809.69 1339.82 1811.5 1339.33 Q1813.33 1338.82 1815.13 1337.82 L1815.13 1341.76 Q1813.35 1342.59 1811.43 1343.01 Q1809.53 1343.43 1807.38 1343.43 Q1801.52 1343.43 1798.07 1339.75 Q1794.62 1336.07 1794.62 1329.82 Q1794.62 1323.47 1798.1 1319.84 Q1801.59 1316.2 1807.66 1316.2 Q1809.62 1316.2 1811.5 1316.62 Q1813.37 1317.01 1815.13 1317.82 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1826.75 1309.47 L1826.75 1316.83 L1835.53 1316.83 L1835.53 1320.14 L1826.75 1320.14 L1826.75 1334.21 Q1826.75 1337.38 1827.61 1338.29 Q1828.49 1339.19 1831.15 1339.19 L1835.53 1339.19 L1835.53 1342.76 L1831.15 1342.76 Q1826.22 1342.76 1824.35 1340.93 Q1822.47 1339.07 1822.47 1334.21 L1822.47 1320.14 L1819.35 1320.14 L1819.35 1316.83 L1822.47 1316.83 L1822.47 1309.47 L1826.75 1309.47 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1860.83 1350.63 L1860.83 1353.94 L1836.2 1353.94 L1836.2 1350.63 L1860.83 1350.63 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1879.85 1320.81 Q1879.14 1320.39 1878.28 1320.21 Q1877.45 1320 1876.43 1320 Q1872.82 1320 1870.87 1322.36 Q1868.95 1324.7 1868.95 1329.1 L1868.95 1342.76 L1864.67 1342.76 L1864.67 1316.83 L1868.95 1316.83 L1868.95 1320.86 Q1870.29 1318.5 1872.45 1317.36 Q1874.6 1316.2 1877.68 1316.2 Q1878.12 1316.2 1878.65 1316.27 Q1879.18 1316.32 1879.83 1316.44 L1879.85 1320.81 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1896.1 1329.72 Q1890.94 1329.72 1888.95 1330.9 Q1886.96 1332.08 1886.96 1334.93 Q1886.96 1337.2 1888.44 1338.54 Q1889.95 1339.86 1892.52 1339.86 Q1896.06 1339.86 1898.19 1337.36 Q1900.34 1334.84 1900.34 1330.67 L1900.34 1329.72 L1896.1 1329.72 M1904.6 1327.96 L1904.6 1342.76 L1900.34 1342.76 L1900.34 1338.82 Q1898.88 1341.18 1896.71 1342.32 Q1894.53 1343.43 1891.38 1343.43 Q1887.4 1343.43 1885.04 1341.2 Q1882.7 1338.96 1882.7 1335.21 Q1882.7 1330.83 1885.62 1328.61 Q1888.56 1326.39 1894.37 1326.39 L1900.34 1326.39 L1900.34 1325.97 Q1900.34 1323.03 1898.4 1321.44 Q1896.47 1319.82 1892.98 1319.82 Q1890.76 1319.82 1888.65 1320.35 Q1886.54 1320.88 1884.6 1321.95 L1884.6 1318.01 Q1886.94 1317.11 1889.14 1316.67 Q1891.34 1316.2 1893.42 1316.2 Q1899.04 1316.2 1901.82 1319.12 Q1904.6 1322.04 1904.6 1327.96 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1934.92 1327.11 L1934.92 1342.76 L1930.66 1342.76 L1930.66 1327.25 Q1930.66 1323.57 1929.23 1321.74 Q1927.79 1319.91 1924.92 1319.91 Q1921.47 1319.91 1919.48 1322.11 Q1917.49 1324.31 1917.49 1328.1 L1917.49 1342.76 L1913.21 1342.76 L1913.21 1316.83 L1917.49 1316.83 L1917.49 1320.86 Q1919.02 1318.52 1921.08 1317.36 Q1923.16 1316.2 1925.87 1316.2 Q1930.34 1316.2 1932.63 1318.98 Q1934.92 1321.74 1934.92 1327.11 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1960.48 1320.76 L1960.48 1306.74 L1964.74 1306.74 L1964.74 1342.76 L1960.48 1342.76 L1960.48 1338.87 Q1959.14 1341.18 1957.08 1342.32 Q1955.04 1343.43 1952.17 1343.43 Q1947.47 1343.43 1944.51 1339.68 Q1941.57 1335.93 1941.57 1329.82 Q1941.57 1323.7 1944.51 1319.95 Q1947.47 1316.2 1952.17 1316.2 Q1955.04 1316.2 1957.08 1317.34 Q1959.14 1318.45 1960.48 1320.76 M1945.97 1329.82 Q1945.97 1334.51 1947.89 1337.2 Q1949.83 1339.86 1953.21 1339.86 Q1956.59 1339.86 1958.53 1337.2 Q1960.48 1334.51 1960.48 1329.82 Q1960.48 1325.12 1958.53 1322.45 Q1956.59 1319.77 1953.21 1319.77 Q1949.83 1319.77 1947.89 1322.45 Q1945.97 1325.12 1945.97 1329.82 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1983.56 1319.82 Q1980.13 1319.82 1978.14 1322.5 Q1976.15 1325.16 1976.15 1329.82 Q1976.15 1334.47 1978.12 1337.15 Q1980.11 1339.82 1983.56 1339.82 Q1986.96 1339.82 1988.95 1337.13 Q1990.94 1334.45 1990.94 1329.82 Q1990.94 1325.21 1988.95 1322.52 Q1986.96 1319.82 1983.56 1319.82 M1983.56 1316.2 Q1989.11 1316.2 1992.28 1319.82 Q1995.46 1323.43 1995.46 1329.82 Q1995.46 1336.18 1992.28 1339.82 Q1989.11 1343.43 1983.56 1343.43 Q1977.98 1343.43 1974.81 1339.82 Q1971.66 1336.18 1971.66 1329.82 Q1971.66 1323.43 1974.81 1319.82 Q1977.98 1316.2 1983.56 1316.2 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2022.7 1321.81 Q2024.3 1318.94 2026.52 1317.57 Q2028.74 1316.2 2031.75 1316.2 Q2035.8 1316.2 2038 1319.05 Q2040.2 1321.88 2040.2 1327.11 L2040.2 1342.76 L2035.92 1342.76 L2035.92 1327.25 Q2035.92 1323.52 2034.6 1321.71 Q2033.28 1319.91 2030.57 1319.91 Q2027.26 1319.91 2025.34 1322.11 Q2023.42 1324.31 2023.42 1328.1 L2023.42 1342.76 L2019.14 1342.76 L2019.14 1327.25 Q2019.14 1323.5 2017.82 1321.71 Q2016.5 1319.91 2013.74 1319.91 Q2010.48 1319.91 2008.56 1322.13 Q2006.64 1324.33 2006.64 1328.1 L2006.64 1342.76 L2002.35 1342.76 L2002.35 1316.83 L2006.64 1316.83 L2006.64 1320.86 Q2008.09 1318.47 2010.13 1317.34 Q2012.17 1316.2 2014.97 1316.2 Q2017.79 1316.2 2019.76 1317.64 Q2021.75 1319.07 2022.7 1321.81 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2068.39 1350.63 L2068.39 1353.94 L2043.77 1353.94 L2043.77 1350.63 L2068.39 1350.63 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2069.34 1316.83 L2073.86 1316.83 L2081.96 1338.59 L2090.06 1316.83 L2094.58 1316.83 L2084.85 1342.76 L2079.07 1342.76 L2069.34 1316.83 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2112.24 1329.72 Q2107.08 1329.72 2105.08 1330.9 Q2103.09 1332.08 2103.09 1334.93 Q2103.09 1337.2 2104.58 1338.54 Q2106.08 1339.86 2108.65 1339.86 Q2112.19 1339.86 2114.32 1337.36 Q2116.47 1334.84 2116.47 1330.67 L2116.47 1329.72 L2112.24 1329.72 M2120.73 1327.96 L2120.73 1342.76 L2116.47 1342.76 L2116.47 1338.82 Q2115.02 1341.18 2112.84 1342.32 Q2110.66 1343.43 2107.52 1343.43 Q2103.53 1343.43 2101.17 1341.2 Q2098.83 1338.96 2098.83 1335.21 Q2098.83 1330.83 2101.75 1328.61 Q2104.69 1326.39 2110.5 1326.39 L2116.47 1326.39 L2116.47 1325.97 Q2116.47 1323.03 2114.53 1321.44 Q2112.61 1319.82 2109.11 1319.82 Q2106.89 1319.82 2104.78 1320.35 Q2102.68 1320.88 2100.73 1321.95 L2100.73 1318.01 Q2103.07 1317.11 2105.27 1316.67 Q2107.47 1316.2 2109.55 1316.2 Q2115.18 1316.2 2117.95 1319.12 Q2120.73 1322.04 2120.73 1327.96 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2129.51 1306.74 L2133.76 1306.74 L2133.76 1342.76 L2129.51 1342.76 L2129.51 1306.74 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2142.24 1332.52 L2142.24 1316.83 L2146.5 1316.83 L2146.5 1332.36 Q2146.5 1336.04 2147.93 1337.89 Q2149.37 1339.72 2152.24 1339.72 Q2155.69 1339.72 2157.68 1337.52 Q2159.69 1335.32 2159.69 1331.53 L2159.69 1316.83 L2163.95 1316.83 L2163.95 1342.76 L2159.69 1342.76 L2159.69 1338.77 Q2158.14 1341.13 2156.08 1342.29 Q2154.04 1343.43 2151.33 1343.43 Q2146.87 1343.43 2144.55 1340.65 Q2142.24 1337.87 2142.24 1332.52 M2152.95 1316.2 L2152.95 1316.2 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2194.9 1328.73 L2194.9 1330.81 L2175.32 1330.81 Q2175.59 1335.21 2177.95 1337.52 Q2180.34 1339.82 2184.57 1339.82 Q2187.03 1339.82 2189.32 1339.21 Q2191.64 1338.61 2193.9 1337.41 L2193.9 1341.44 Q2191.61 1342.41 2189.2 1342.92 Q2186.8 1343.43 2184.32 1343.43 Q2178.12 1343.43 2174.48 1339.82 Q2170.87 1336.2 2170.87 1330.05 Q2170.87 1323.68 2174.3 1319.95 Q2177.75 1316.2 2183.58 1316.2 Q2188.81 1316.2 2191.84 1319.58 Q2194.9 1322.94 2194.9 1328.73 M2190.64 1327.48 Q2190.59 1323.98 2188.67 1321.9 Q2186.77 1319.82 2183.63 1319.82 Q2180.06 1319.82 2177.91 1321.83 Q2175.78 1323.84 2175.45 1327.5 L2190.64 1327.48 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the evaluation_df to include only the SimpleLearnedHeuristic\n",
    "learned_heuristic_df = filter(row -> row[:heuristic_type] == \"SimpleLearnedHeuristic\", evaluation_df)\n",
    "# Filter the evaluation_df to include only the BasicHeuristic(selectMax)\n",
    "select_max_df = filter(row -> row[:heuristic_type] == \"BasicHeuristic(selectMax)\", evaluation_df)\n",
    "# Filter the evaluation_df to include only the BasicHeuristic(select_random_value)\n",
    "random_heuristic_df = filter(row -> row[:heuristic_type] == \"BasicHeuristic(select_random_value)\", evaluation_df)\n",
    "\n",
    "# Create a line plot of the first solution for each instance for all heuristics\n",
    "scatter()\n",
    "scatter!(learned_heuristic_df[!, :num_instance], -learned_heuristic_df[!, :first_sol], label=\"SimpleLearnedHeuristic\", markersize=8)\n",
    "scatter!(select_max_df[!, :num_instance], -select_max_df[!, :first_sol], label=\"selectMax\")\n",
    "scatter!(random_heuristic_df[!, :num_instance], -random_heuristic_df[!, :first_sol], label=\"select_random_value\")\n",
    "xlabel!(\"Instance Number\")\n",
    "ylabel!(\"First Solution\")\n",
    "xticks!(1:maximum(evaluation_df[!, :num_instance]), visible=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Large Problems with Pre-Trained Model\n",
    "\n",
    "The last example was on trivially small problems. Now let's have a look at the performance of learned heuristics on larger problems. For this section, we will load a model trained on MIS problems with 40 nodes and we will be comparing the performance of the learned heuristc with random heuristics and the select max heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_mis40_40_4_100.bson\n",
      "Evaluation with strategy : SeaPearl.DFSearch()\n",
      "Switching to agent : SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput}SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 4459 nodes, taken 3.7500367s, number of solutions found : 2\n",
      "SeaPearl.SimpleLearnedHeuristic{SeaPearl.HeterogeneousStateRepresentation{SeaPearl.DefaultFeaturization, SeaPearl.HeterogeneousTrajectoryState}, SeaPearl.GeneralReward, SeaPearl.FixedOutput} evaluated with: 8019 nodes, taken 6.5894169s, number of solutions found : 2"
     ]
    }
   ],
   "source": [
    "validation_generator = SeaPearl.MaximumIndependentSetGenerator(40, 4)\n",
    "num_instances = 20 # Number of instances to evaluate on\n",
    "node_budget = 10000 # Budget of visited nodes\n",
    "take_objective = false # Set it to true if we have to branch on the object ive variable\n",
    "eval_strategy = SeaPearl.DFSearch()\n",
    "include_dfs = true # Set it to true if you want to evaluate with DFS in addition to ILDS\n",
    "basicHeuristics = Dict()\n",
    "num_random_heuristics = 2\n",
    "\n",
    "for (i, random_heuristic) in enumerate(randomHeuristics)\n",
    "    push!(basicHeuristics, \"random\" * string(i) => random_heuristic)\n",
    "end\n",
    "\n",
    "\n",
    "folder = \"./models\"\n",
    "models = []\n",
    "for file in readdir(folder)\n",
    "    if splitext(file)[2] == \".bson\"\n",
    "        println(folder * \"/\" * file)\n",
    "        @load folder * \"/\" * file model\n",
    "        push!(models, model)\n",
    "    end\n",
    "end\n",
    "\n",
    "for (i, random_heuristic) in enumerate(randomHeuristics)\n",
    "    push!(basicHeuristics, \"random\" * string(i) => random_heuristic)\n",
    "end\n",
    "\n",
    "push!(basicHeuristics, \"max\" => heuristic_max)\n",
    "evaluation_df = benchmark(\n",
    "    models=models,\n",
    "    evaluation_folder=pwd(),\n",
    "    num_instances=num_instances,\n",
    "    chosen_features=chosen_features,\n",
    "    take_objective=take_objective,\n",
    "    generator=validation_generator,\n",
    "    basicHeuristics=basicHeuristics,\n",
    "    save_experiment_metrics=false,\n",
    "    include_dfs=include_dfs,\n",
    "    budget=node_budget,\n",
    "    ILDS=eval_strategy\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at results\n",
    "\n",
    "We have now loaded a model trained on MIS problems with 40 nodes. Let's have a look at the performance of the learned heuristic vs random and select max heuristic over the course of the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadOnlyMemoryError",
     "evalue": "ReadOnlyMemoryError()",
     "output_type": "error",
     "traceback": [
      "ReadOnlyMemoryError()",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\libcuda.jl:138 [inlined]",
      "  [2] macro expansion",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\error.jl:95 [inlined]",
      "  [3] cuCtxSetCurrent",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\utils\\call.jl:26 [inlined]",
      "  [4] activate",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\context.jl:181 [inlined]",
      "  [5] context!(ctx::CUDA.CuContext)",
      "    @ CUDA C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\state.jl:143",
      "  [6] #context!#63",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\state.jl:162 [inlined]",
      "  [7] context!",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\state.jl:159 [inlined]",
      "  [8] unsafe_copyto!(dest::Matrix{Float32}, doffs::Int64, src::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, soffs::Int64, n::Int64)",
      "    @ CUDA C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\src\\array.jl:406",
      "  [9] copyto!",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\src\\array.jl:360 [inlined]",
      " [10] copyto!",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\src\\array.jl:364 [inlined]",
      " [11] copyto_axcheck!(dest::Matrix{Float32}, src::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Base .\\abstractarray.jl:1127",
      " [12] Array",
      "    @ .\\array.jl:626 [inlined]",
      " [13] Array",
      "    @ .\\boot.jl:483 [inlined]",
      " [14] convert",
      "    @ .\\array.jl:617 [inlined]",
      " [15] adapt_storage",
      "    @ C:\\Users\\leobo\\.julia\\packages\\GPUArrays\\5XhED\\src\\host\\abstractarray.jl:23 [inlined]",
      " [16] adapt_structure",
      "    @ C:\\Users\\leobo\\.julia\\packages\\Adapt\\UtItS\\src\\Adapt.jl:57 [inlined]",
      " [17] adapt",
      "    @ C:\\Users\\leobo\\.julia\\packages\\Adapt\\UtItS\\src\\Adapt.jl:40 [inlined]",
      " [18] _show_nonempty",
      "    @ C:\\Users\\leobo\\.julia\\packages\\GPUArrays\\5XhED\\src\\host\\abstractarray.jl:30 [inlined]",
      " [19] show(io::IOContext{IOBuffer}, X::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Base .\\arrayshow.jl:489",
      " [20] _show_default(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [21] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [22] show(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [23] _show_default(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [24] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [25] show(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [26] _show_default(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [27] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [28] show(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [29] _show_default(io::IOContext{IOBuffer}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [30] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [31] show",
      "    @ .\\show.jl:391 [inlined]",
      " [32] show",
      "    @ .\\multimedia.jl:47 [inlined]",
      " [33] limitstringmime(mime::MIME{Symbol(\"text/plain\")}, x::NeuralNetworkApproximator{SeaPearl.HeterogeneousFullFeaturedCPNN, ADAM})",
      "    @ IJulia C:\\Users\\leobo\\.julia\\packages\\IJulia\\6TIq1\\src\\inline.jl:43",
      " [34] display_mimestring",
      "    @ C:\\Users\\leobo\\.julia\\packages\\IJulia\\6TIq1\\src\\display.jl:71 [inlined]",
      " [35] display_dict(x::NeuralNetworkApproximator{SeaPearl.HeterogeneousFullFeaturedCPNN, ADAM})",
      "    @ IJulia C:\\Users\\leobo\\.julia\\packages\\IJulia\\6TIq1\\src\\display.jl:102",
      " [36] #invokelatest#2",
      "    @ .\\essentials.jl:729 [inlined]",
      " [37] invokelatest",
      "    @ .\\essentials.jl:726 [inlined]",
      " [38] execute_request(socket::ZMQ.Socket, msg::IJulia.Msg)",
      "    @ IJulia C:\\Users\\leobo\\.julia\\packages\\IJulia\\6TIq1\\src\\execute_request.jl:112",
      " [39] #invokelatest#2",
      "    @ .\\essentials.jl:729 [inlined]",
      " [40] invokelatest",
      "    @ .\\essentials.jl:726 [inlined]",
      " [41] eventloop(socket::ZMQ.Socket)",
      "    @ IJulia C:\\Users\\leobo\\.julia\\packages\\IJulia\\6TIq1\\src\\eventloop.jl:8",
      " [42] (::IJulia.var\"#15#18\")()",
      "    @ IJulia .\\task.jl:484"
     ]
    }
   ],
   "source": [
    "\n",
    "# RL.NeuralNetworkApproximator(\n",
    "#     model=models[1],\n",
    "#     optimizer=ADAM()\n",
    "# ) |> cpu\n",
    "# for (i, model) in enumerate(models)\n",
    "#     agent = RL.Agent(\n",
    "#         policy=RL.QBasedPolicy(\n",
    "#             learner=RL.DQNLearner(\n",
    "#                 approximator=RL.NeuralNetworkApproximator(\n",
    "#                     model=model,\n",
    "#                     optimizer=ADAM()\n",
    "#                 ) |> cpu,\n",
    "#                 target_approximator=RL.NeuralNetworkApproximator(\n",
    "#                     model=model,\n",
    "#                     optimizer=ADAM()\n",
    "#                 ) |> cpu,\n",
    "#                 loss_func=Flux.Losses.huber_loss\n",
    "#             ),\n",
    "#             explorer=RL.EpsilonGreedyExplorer(\n",
    "#                 ϵ_stable=0.0\n",
    "#             )\n",
    "#         ),\n",
    "#         trajectory=RL.CircularArraySLARTTrajectory(\n",
    "#             capacity=1,\n",
    "#             state=SeaPearl.DefaultTrajectoryState[] => (),\n",
    "#             legal_actions_mask=Vector{Bool} => (1,),\n",
    "#         )\n",
    "#         )\n",
    "# end\n",
    "\n",
    "# evaluation_df = benchmark(\n",
    "#     models=[models[1]],\n",
    "#     evaluation_folder=pwd(),\n",
    "#     num_instances=num_instances,\n",
    "#     chosen_features=chosen_features,\n",
    "#     take_objective=take_objective,\n",
    "#     generator=validation_generator,\n",
    "#     basicHeuristics=basicHeuristics,\n",
    "#     save_experiment_metrics=false,\n",
    "#     include_dfs=include_dfs,\n",
    "#     budget=node_budget,\n",
    "#     ILDS=eval_strategy\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[NeuralNetworkApproximator{SeaPearl.HeterogeneousFullFeaturedCPNN, ADAM}(SeaPearl.HeterogeneousFullFeaturedCPNN(HeterogeneousModel{SeaPearl.HeterogeneousGraphConvInit{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, SeaPearl.HeterogeneousGraphConv{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, SeaPearl.meanPooling}}(SeaPearl.HeterogeneousGraphConvInit{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}("
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "ReadOnlyMemoryError()",
     "output_type": "error",
     "traceback": [
      "ReadOnlyMemoryError()",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\libcuda.jl:138 [inlined]",
      "  [2] macro expansion",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\error.jl:95 [inlined]",
      "  [3] cuCtxSetCurrent",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\utils\\call.jl:26 [inlined]",
      "  [4] activate",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\context.jl:181 [inlined]",
      "  [5] context!(ctx::CUDA.CuContext)",
      "    @ CUDA C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\state.jl:143",
      "  [6] #context!#63",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\state.jl:162 [inlined]",
      "  [7] context!",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\lib\\cudadrv\\state.jl:159 [inlined]",
      "  [8] unsafe_copyto!(dest::Matrix{Float32}, doffs::Int64, src::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, soffs::Int64, n::Int64)",
      "    @ CUDA C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\src\\array.jl:406",
      "  [9] copyto!",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\src\\array.jl:360 [inlined]",
      " [10] copyto!",
      "    @ C:\\Users\\leobo\\.julia\\packages\\CUDA\\BbliS\\src\\array.jl:364 [inlined]",
      " [11] copyto_axcheck!(dest::Matrix{Float32}, src::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Base .\\abstractarray.jl:1127",
      " [12] Array",
      "    @ .\\array.jl:626 [inlined]",
      " [13] Array",
      "    @ .\\boot.jl:483 [inlined]",
      " [14] convert",
      "    @ .\\array.jl:617 [inlined]",
      " [15] adapt_storage",
      "    @ C:\\Users\\leobo\\.julia\\packages\\GPUArrays\\5XhED\\src\\host\\abstractarray.jl:23 [inlined]",
      " [16] adapt_structure",
      "    @ C:\\Users\\leobo\\.julia\\packages\\Adapt\\UtItS\\src\\Adapt.jl:57 [inlined]",
      " [17] adapt",
      "    @ C:\\Users\\leobo\\.julia\\packages\\Adapt\\UtItS\\src\\Adapt.jl:40 [inlined]",
      " [18] _show_nonempty",
      "    @ C:\\Users\\leobo\\.julia\\packages\\GPUArrays\\5XhED\\src\\host\\abstractarray.jl:30 [inlined]",
      " [19] show(io::IOContext{Base.PipeEndpoint}, X::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Base .\\arrayshow.jl:489",
      " [20] _show_default(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [21] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [22] show(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [23] _show_default(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [24] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [25] show(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [26] _show_default(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [27] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [28] show(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [29] _show_default(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:413",
      " [30] show_default",
      "    @ .\\show.jl:396 [inlined]",
      " [31] show(io::IOContext{Base.PipeEndpoint}, x::Any)",
      "    @ Base .\\show.jl:391",
      " [32] show_delim_array(io::IOContext{Base.PipeEndpoint}, itr::Vector{Any}, op::Char, delim::String, cl::Char, delim_one::Bool, i1::Int64, l::Int64)",
      "    @ Base .\\show.jl:1212",
      " [33] show_delim_array",
      "    @ .\\show.jl:1201 [inlined]",
      " [34] show_vector(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, v::Vector{Any}, opn::Char, cls::Char)",
      "    @ Base .\\arrayshow.jl:528",
      " [35] show_vector",
      "    @ .\\arrayshow.jl:513 [inlined]",
      " [36] show",
      "    @ .\\arrayshow.jl:484 [inlined]",
      " [37] print(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, x::Vector{Any})",
      "    @ Base .\\strings\\io.jl:35",
      " [38] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Vector{Any}, ::String)",
      "    @ Base .\\strings\\io.jl:46",
      " [39] println(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, xs::Vector{Any})",
      "    @ Base .\\strings\\io.jl:75",
      " [40] println(xs::Vector{Any})",
      "    @ Base .\\coreio.jl:4",
      " [41] top-level scope",
      "    @ In[77]:1"
     ]
    }
   ],
   "source": [
    "println(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
